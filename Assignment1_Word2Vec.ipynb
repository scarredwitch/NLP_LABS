{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Try a real corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to C:\\Users\\Sirikit\n",
      "[nltk_data]     Joshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package abc is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import abc\n",
    "nltk.download('abc')\n",
    "corpus = nltk.corpus.abc.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766811\n"
     ]
    }
   ],
   "source": [
    "#let's check the size of the corpus\n",
    "print(len(corpus))\n",
    "corpus_para = corpus[0:500]\n",
    "\n",
    "corpus_lower = [[word.lower() for word in corpus_para]]\n",
    "# print(corpus_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pm', 'denies', 'knowledge', 'of', 'awb']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizing list of words\n",
    "word_list = []\n",
    "for sent in corpus_lower:\n",
    "    for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "word_list[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['was', 'average', 'its', 'all', 'denied']\n",
      "248\n"
     ]
    }
   ],
   "source": [
    "#2. numericalize\n",
    "\n",
    "#2.1 get all the unique words\n",
    "#we want to flatten this (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs  = list(set(flatten(corpus_lower)))  #vocabs is a term defining all unique words your system know\n",
    "print(vocabs[0:5])\n",
    "print(len(vocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 assign id to all these vocabs\n",
    "word2index = {v: idx+1 for idx, v in enumerate(vocabs)}\n",
    "\n",
    "#add <UNK>, which is a very normal token exists in the world\n",
    "vocabs.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKKK, or anything\n",
    "\n",
    "word2index['<UNK>'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'was': 1,\n",
       " 'average': 2,\n",
       " 'its': 3,\n",
       " 'all': 4,\n",
       " 'denied': 5,\n",
       " 'valuable': 6,\n",
       " 'australia': 7,\n",
       " ',\"': 8,\n",
       " 'prices': 9,\n",
       " 'prove': 10,\n",
       " 'although': 11,\n",
       " 'put': 12,\n",
       " '.\"': 13,\n",
       " 's': 14,\n",
       " 'people': 15,\n",
       " 'trade': 16,\n",
       " 'market': 17,\n",
       " 'south': 18,\n",
       " 'company': 19,\n",
       " 'hands': 20,\n",
       " 'broadly': 21,\n",
       " 'trading': 22,\n",
       " 'grain': 23,\n",
       " 'forwarded': 24,\n",
       " 'been': 25,\n",
       " 'from': 26,\n",
       " 'too': 27,\n",
       " 'approached': 28,\n",
       " 'skimmed': 29,\n",
       " 'multinationals': 30,\n",
       " 'analyst': 31,\n",
       " 'with': 32,\n",
       " 'into': 33,\n",
       " 'provide': 34,\n",
       " 'desk': 35,\n",
       " 'totalled': 36,\n",
       " 'of': 37,\n",
       " 'aside': 38,\n",
       " 'knew': 39,\n",
       " 'knowledge': 40,\n",
       " 'show': 41,\n",
       " 'things': 42,\n",
       " 'another': 43,\n",
       " 'biggest': 44,\n",
       " 'coalition': 45,\n",
       " 'minister': 46,\n",
       " 'take': 47,\n",
       " 'else': 48,\n",
       " 'grains': 49,\n",
       " 'stories': 50,\n",
       " 'close': 51,\n",
       " 'astonishing': 52,\n",
       " 'wheat': 53,\n",
       " 'but': 54,\n",
       " 'i': 55,\n",
       " 'released': 56,\n",
       " 'did': 57,\n",
       " 'not': 58,\n",
       " 'to': 59,\n",
       " 'mr': 60,\n",
       " 'pretty': 61,\n",
       " 'best': 62,\n",
       " 'vaile': 63,\n",
       " 'ploy': 64,\n",
       " 'has': 65,\n",
       " 'east': 66,\n",
       " 'million': 67,\n",
       " 'indicated': 68,\n",
       " 'must': 69,\n",
       " 'producers': 70,\n",
       " ',': 71,\n",
       " 'asks': 72,\n",
       " 'lindberg': 73,\n",
       " 'future': 74,\n",
       " 'today': 75,\n",
       " 'new': 76,\n",
       " 'there': 77,\n",
       " 'hadn': 78,\n",
       " 'two': 79,\n",
       " '2002': 80,\n",
       " 'it': 81,\n",
       " 'growers': 82,\n",
       " 'for': 83,\n",
       " 'sent': 84,\n",
       " 'time': 85,\n",
       " 'they': 86,\n",
       " 'connor': 87,\n",
       " '-': 88,\n",
       " 'think': 89,\n",
       " 'denies': 90,\n",
       " 'taking': 91,\n",
       " 'sales': 92,\n",
       " 'responsibility': 93,\n",
       " 'among': 94,\n",
       " 'as': 95,\n",
       " 'iraq': 96,\n",
       " 'oil': 97,\n",
       " 'he': 98,\n",
       " 'this': 99,\n",
       " 'actually': 100,\n",
       " 'paying': 101,\n",
       " 'kickbacks': 102,\n",
       " 'exporter': 103,\n",
       " '$': 104,\n",
       " 'howard': 105,\n",
       " 'inquiring': 106,\n",
       " 'are': 107,\n",
       " 'john': 108,\n",
       " 'have': 109,\n",
       " 'performed': 110,\n",
       " 'is': 111,\n",
       " 'same': 112,\n",
       " 'government': 113,\n",
       " 'cole': 114,\n",
       " 'may': 115,\n",
       " 'board': 116,\n",
       " 'deputy': 117,\n",
       " 'very': 118,\n",
       " 'questions': 119,\n",
       " 'the': 120,\n",
       " 'remain': 121,\n",
       " 'countries': 122,\n",
       " '20': 123,\n",
       " 'director': 124,\n",
       " 'interests': 125,\n",
       " 'lay': 126,\n",
       " 'will': 127,\n",
       " 'someone': 128,\n",
       " 'gavan': 129,\n",
       " 'commission': 130,\n",
       " 'managing': 131,\n",
       " 'at': 132,\n",
       " 'would': 133,\n",
       " 'possibly': 134,\n",
       " 'geary': 135,\n",
       " 'prime': 136,\n",
       " 'peter': 137,\n",
       " 'by': 138,\n",
       " 'well': 139,\n",
       " 'says': 140,\n",
       " 'wales': 141,\n",
       " 'say': 142,\n",
       " 'food': 143,\n",
       " 'business': 144,\n",
       " '\"': 145,\n",
       " 'if': 146,\n",
       " '2000': 147,\n",
       " '.': 148,\n",
       " 'that': 149,\n",
       " 'feet': 150,\n",
       " 'squarely': 151,\n",
       " 'get': 152,\n",
       " 'attempts': 153,\n",
       " 'pm': 154,\n",
       " 'questioned': 155,\n",
       " 'illicit': 156,\n",
       " 'had': 157,\n",
       " 'about': 158,\n",
       " 'letters': 159,\n",
       " 'predicts': 160,\n",
       " 'one': 161,\n",
       " 'awb': 162,\n",
       " 'tonne': 163,\n",
       " 'on': 164,\n",
       " 'o': 165,\n",
       " 'do': 166,\n",
       " 't': 167,\n",
       " 'manager': 168,\n",
       " 'western': 169,\n",
       " 'wipe': 170,\n",
       " 'mark': 171,\n",
       " 'and': 172,\n",
       " 'central': 173,\n",
       " 'done': 174,\n",
       " 'program': 175,\n",
       " 'can': 176,\n",
       " 'informed': 177,\n",
       " 'a': 178,\n",
       " '\".': 179,\n",
       " 'opposition': 180,\n",
       " 'longer': 181,\n",
       " 'products': 182,\n",
       " 'remember': 183,\n",
       " 'which': 184,\n",
       " 'ministers': 185,\n",
       " 'in': 186,\n",
       " 'payments': 187,\n",
       " 'their': 188,\n",
       " 'system': 189,\n",
       " 'going': 190,\n",
       " 'advantage': 191,\n",
       " 'way': 192,\n",
       " 'moment': 193,\n",
       " 've': 194,\n",
       " '290': 195,\n",
       " 'received': 196,\n",
       " 'still': 197,\n",
       " 'writing': 198,\n",
       " 'back': 199,\n",
       " 'agriculture': 200,\n",
       " 'them': 201,\n",
       " 'whether': 202,\n",
       " 'though': 203,\n",
       " 'thing': 204,\n",
       " 'anything': 205,\n",
       " 'jordanian': 206,\n",
       " 'despite': 207,\n",
       " 'preserve': 208,\n",
       " 'inquiry': 209,\n",
       " 'single': 210,\n",
       " 'fair': 211,\n",
       " 'be': 212,\n",
       " 'after': 213,\n",
       " 'andrew': 214,\n",
       " 'said': 215,\n",
       " 'kept': 216,\n",
       " 'fully': 217,\n",
       " 'colleagues': 218,\n",
       " 'try': 219,\n",
       " 'producer': 220,\n",
       " 'email': 221,\n",
       " 'overseas': 222,\n",
       " 'foothold': 223,\n",
       " 'middle': 224,\n",
       " 'service': 225,\n",
       " 'asian': 226,\n",
       " 'plenty': 227,\n",
       " 'could': 228,\n",
       " 'everything': 229,\n",
       " 'drop': 230,\n",
       " 'an': 231,\n",
       " 'contact': 232,\n",
       " \"'\": 233,\n",
       " 'iraqi': 234,\n",
       " 'got': 235,\n",
       " 'over': 236,\n",
       " 'asking': 237,\n",
       " 'revelations': 238,\n",
       " 'letter': 239,\n",
       " 'd': 240,\n",
       " 'fairly': 241,\n",
       " 'round': 242,\n",
       " 'reading': 243,\n",
       " 'much': 244,\n",
       " 'trucking': 245,\n",
       " 'give': 246,\n",
       " 'reasonable': 247,\n",
       " 'support': 248,\n",
       " '<UNK>': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'was',\n",
       " 2: 'average',\n",
       " 3: 'its',\n",
       " 4: 'all',\n",
       " 5: 'denied',\n",
       " 6: 'valuable',\n",
       " 7: 'australia',\n",
       " 8: ',\"',\n",
       " 9: 'prices',\n",
       " 10: 'prove',\n",
       " 11: 'although',\n",
       " 12: 'put',\n",
       " 13: '.\"',\n",
       " 14: 's',\n",
       " 15: 'people',\n",
       " 16: 'trade',\n",
       " 17: 'market',\n",
       " 18: 'south',\n",
       " 19: 'company',\n",
       " 20: 'hands',\n",
       " 21: 'broadly',\n",
       " 22: 'trading',\n",
       " 23: 'grain',\n",
       " 24: 'forwarded',\n",
       " 25: 'been',\n",
       " 26: 'from',\n",
       " 27: 'too',\n",
       " 28: 'approached',\n",
       " 29: 'skimmed',\n",
       " 30: 'multinationals',\n",
       " 31: 'analyst',\n",
       " 32: 'with',\n",
       " 33: 'into',\n",
       " 34: 'provide',\n",
       " 35: 'desk',\n",
       " 36: 'totalled',\n",
       " 37: 'of',\n",
       " 38: 'aside',\n",
       " 39: 'knew',\n",
       " 40: 'knowledge',\n",
       " 41: 'show',\n",
       " 42: 'things',\n",
       " 43: 'another',\n",
       " 44: 'biggest',\n",
       " 45: 'coalition',\n",
       " 46: 'minister',\n",
       " 47: 'take',\n",
       " 48: 'else',\n",
       " 49: 'grains',\n",
       " 50: 'stories',\n",
       " 51: 'close',\n",
       " 52: 'astonishing',\n",
       " 53: 'wheat',\n",
       " 54: 'but',\n",
       " 55: 'i',\n",
       " 56: 'released',\n",
       " 57: 'did',\n",
       " 58: 'not',\n",
       " 59: 'to',\n",
       " 60: 'mr',\n",
       " 61: 'pretty',\n",
       " 62: 'best',\n",
       " 63: 'vaile',\n",
       " 64: 'ploy',\n",
       " 65: 'has',\n",
       " 66: 'east',\n",
       " 67: 'million',\n",
       " 68: 'indicated',\n",
       " 69: 'must',\n",
       " 70: 'producers',\n",
       " 71: ',',\n",
       " 72: 'asks',\n",
       " 73: 'lindberg',\n",
       " 74: 'future',\n",
       " 75: 'today',\n",
       " 76: 'new',\n",
       " 77: 'there',\n",
       " 78: 'hadn',\n",
       " 79: 'two',\n",
       " 80: '2002',\n",
       " 81: 'it',\n",
       " 82: 'growers',\n",
       " 83: 'for',\n",
       " 84: 'sent',\n",
       " 85: 'time',\n",
       " 86: 'they',\n",
       " 87: 'connor',\n",
       " 88: '-',\n",
       " 89: 'think',\n",
       " 90: 'denies',\n",
       " 91: 'taking',\n",
       " 92: 'sales',\n",
       " 93: 'responsibility',\n",
       " 94: 'among',\n",
       " 95: 'as',\n",
       " 96: 'iraq',\n",
       " 97: 'oil',\n",
       " 98: 'he',\n",
       " 99: 'this',\n",
       " 100: 'actually',\n",
       " 101: 'paying',\n",
       " 102: 'kickbacks',\n",
       " 103: 'exporter',\n",
       " 104: '$',\n",
       " 105: 'howard',\n",
       " 106: 'inquiring',\n",
       " 107: 'are',\n",
       " 108: 'john',\n",
       " 109: 'have',\n",
       " 110: 'performed',\n",
       " 111: 'is',\n",
       " 112: 'same',\n",
       " 113: 'government',\n",
       " 114: 'cole',\n",
       " 115: 'may',\n",
       " 116: 'board',\n",
       " 117: 'deputy',\n",
       " 118: 'very',\n",
       " 119: 'questions',\n",
       " 120: 'the',\n",
       " 121: 'remain',\n",
       " 122: 'countries',\n",
       " 123: '20',\n",
       " 124: 'director',\n",
       " 125: 'interests',\n",
       " 126: 'lay',\n",
       " 127: 'will',\n",
       " 128: 'someone',\n",
       " 129: 'gavan',\n",
       " 130: 'commission',\n",
       " 131: 'managing',\n",
       " 132: 'at',\n",
       " 133: 'would',\n",
       " 134: 'possibly',\n",
       " 135: 'geary',\n",
       " 136: 'prime',\n",
       " 137: 'peter',\n",
       " 138: 'by',\n",
       " 139: 'well',\n",
       " 140: 'says',\n",
       " 141: 'wales',\n",
       " 142: 'say',\n",
       " 143: 'food',\n",
       " 144: 'business',\n",
       " 145: '\"',\n",
       " 146: 'if',\n",
       " 147: '2000',\n",
       " 148: '.',\n",
       " 149: 'that',\n",
       " 150: 'feet',\n",
       " 151: 'squarely',\n",
       " 152: 'get',\n",
       " 153: 'attempts',\n",
       " 154: 'pm',\n",
       " 155: 'questioned',\n",
       " 156: 'illicit',\n",
       " 157: 'had',\n",
       " 158: 'about',\n",
       " 159: 'letters',\n",
       " 160: 'predicts',\n",
       " 161: 'one',\n",
       " 162: 'awb',\n",
       " 163: 'tonne',\n",
       " 164: 'on',\n",
       " 165: 'o',\n",
       " 166: 'do',\n",
       " 167: 't',\n",
       " 168: 'manager',\n",
       " 169: 'western',\n",
       " 170: 'wipe',\n",
       " 171: 'mark',\n",
       " 172: 'and',\n",
       " 173: 'central',\n",
       " 174: 'done',\n",
       " 175: 'program',\n",
       " 176: 'can',\n",
       " 177: 'informed',\n",
       " 178: 'a',\n",
       " 179: '\".',\n",
       " 180: 'opposition',\n",
       " 181: 'longer',\n",
       " 182: 'products',\n",
       " 183: 'remember',\n",
       " 184: 'which',\n",
       " 185: 'ministers',\n",
       " 186: 'in',\n",
       " 187: 'payments',\n",
       " 188: 'their',\n",
       " 189: 'system',\n",
       " 190: 'going',\n",
       " 191: 'advantage',\n",
       " 192: 'way',\n",
       " 193: 'moment',\n",
       " 194: 've',\n",
       " 195: '290',\n",
       " 196: 'received',\n",
       " 197: 'still',\n",
       " 198: 'writing',\n",
       " 199: 'back',\n",
       " 200: 'agriculture',\n",
       " 201: 'them',\n",
       " 202: 'whether',\n",
       " 203: 'though',\n",
       " 204: 'thing',\n",
       " 205: 'anything',\n",
       " 206: 'jordanian',\n",
       " 207: 'despite',\n",
       " 208: 'preserve',\n",
       " 209: 'inquiry',\n",
       " 210: 'single',\n",
       " 211: 'fair',\n",
       " 212: 'be',\n",
       " 213: 'after',\n",
       " 214: 'andrew',\n",
       " 215: 'said',\n",
       " 216: 'kept',\n",
       " 217: 'fully',\n",
       " 218: 'colleagues',\n",
       " 219: 'try',\n",
       " 220: 'producer',\n",
       " 221: 'email',\n",
       " 222: 'overseas',\n",
       " 223: 'foothold',\n",
       " 224: 'middle',\n",
       " 225: 'service',\n",
       " 226: 'asian',\n",
       " 227: 'plenty',\n",
       " 228: 'could',\n",
       " 229: 'everything',\n",
       " 230: 'drop',\n",
       " 231: 'an',\n",
       " 232: 'contact',\n",
       " 233: \"'\",\n",
       " 234: 'iraqi',\n",
       " 235: 'got',\n",
       " 236: 'over',\n",
       " 237: 'asking',\n",
       " 238: 'revelations',\n",
       " 239: 'letter',\n",
       " 240: 'd',\n",
       " 241: 'fairly',\n",
       " 242: 'round',\n",
       " 243: 'reading',\n",
       " 244: 'much',\n",
       " 245: 'trucking',\n",
       " 246: 'give',\n",
       " 247: 'reasonable',\n",
       " 248: 'support',\n",
       " 0: '<UNK>'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create index2word dictionary\n",
    "   \n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['was',\n",
       " 'average',\n",
       " 'its',\n",
       " 'all',\n",
       " 'denied',\n",
       " 'valuable',\n",
       " 'australia',\n",
       " ',\"',\n",
       " 'prices',\n",
       " 'prove',\n",
       " 'although',\n",
       " 'put',\n",
       " '.\"',\n",
       " 's',\n",
       " 'people',\n",
       " 'trade',\n",
       " 'market',\n",
       " 'south',\n",
       " 'company',\n",
       " 'hands',\n",
       " 'broadly',\n",
       " 'trading',\n",
       " 'grain',\n",
       " 'forwarded',\n",
       " 'been',\n",
       " 'from',\n",
       " 'too',\n",
       " 'approached',\n",
       " 'skimmed',\n",
       " 'multinationals',\n",
       " 'analyst',\n",
       " 'with',\n",
       " 'into',\n",
       " 'provide',\n",
       " 'desk',\n",
       " 'totalled',\n",
       " 'of',\n",
       " 'aside',\n",
       " 'knew',\n",
       " 'knowledge',\n",
       " 'show',\n",
       " 'things',\n",
       " 'another',\n",
       " 'biggest',\n",
       " 'coalition',\n",
       " 'minister',\n",
       " 'take',\n",
       " 'else',\n",
       " 'grains',\n",
       " 'stories',\n",
       " 'close',\n",
       " 'astonishing',\n",
       " 'wheat',\n",
       " 'but',\n",
       " 'i',\n",
       " 'released',\n",
       " 'did',\n",
       " 'not',\n",
       " 'to',\n",
       " 'mr',\n",
       " 'pretty',\n",
       " 'best',\n",
       " 'vaile',\n",
       " 'ploy',\n",
       " 'has',\n",
       " 'east',\n",
       " 'million',\n",
       " 'indicated',\n",
       " 'must',\n",
       " 'producers',\n",
       " ',',\n",
       " 'asks',\n",
       " 'lindberg',\n",
       " 'future',\n",
       " 'today',\n",
       " 'new',\n",
       " 'there',\n",
       " 'hadn',\n",
       " 'two',\n",
       " '2002',\n",
       " 'it',\n",
       " 'growers',\n",
       " 'for',\n",
       " 'sent',\n",
       " 'time',\n",
       " 'they',\n",
       " 'connor',\n",
       " '-',\n",
       " 'think',\n",
       " 'denies',\n",
       " 'taking',\n",
       " 'sales',\n",
       " 'responsibility',\n",
       " 'among',\n",
       " 'as',\n",
       " 'iraq',\n",
       " 'oil',\n",
       " 'he',\n",
       " 'this',\n",
       " 'actually',\n",
       " 'paying',\n",
       " 'kickbacks',\n",
       " 'exporter',\n",
       " '$',\n",
       " 'howard',\n",
       " 'inquiring',\n",
       " 'are',\n",
       " 'john',\n",
       " 'have',\n",
       " 'performed',\n",
       " 'is',\n",
       " 'same',\n",
       " 'government',\n",
       " 'cole',\n",
       " 'may',\n",
       " 'board',\n",
       " 'deputy',\n",
       " 'very',\n",
       " 'questions',\n",
       " 'the',\n",
       " 'remain',\n",
       " 'countries',\n",
       " '20',\n",
       " 'director',\n",
       " 'interests',\n",
       " 'lay',\n",
       " 'will',\n",
       " 'someone',\n",
       " 'gavan',\n",
       " 'commission',\n",
       " 'managing',\n",
       " 'at',\n",
       " 'would',\n",
       " 'possibly',\n",
       " 'geary',\n",
       " 'prime',\n",
       " 'peter',\n",
       " 'by',\n",
       " 'well',\n",
       " 'says',\n",
       " 'wales',\n",
       " 'say',\n",
       " 'food',\n",
       " 'business',\n",
       " '\"',\n",
       " 'if',\n",
       " '2000',\n",
       " '.',\n",
       " 'that',\n",
       " 'feet',\n",
       " 'squarely',\n",
       " 'get',\n",
       " 'attempts',\n",
       " 'pm',\n",
       " 'questioned',\n",
       " 'illicit',\n",
       " 'had',\n",
       " 'about',\n",
       " 'letters',\n",
       " 'predicts',\n",
       " 'one',\n",
       " 'awb',\n",
       " 'tonne',\n",
       " 'on',\n",
       " 'o',\n",
       " 'do',\n",
       " 't',\n",
       " 'manager',\n",
       " 'western',\n",
       " 'wipe',\n",
       " 'mark',\n",
       " 'and',\n",
       " 'central',\n",
       " 'done',\n",
       " 'program',\n",
       " 'can',\n",
       " 'informed',\n",
       " 'a',\n",
       " '\".',\n",
       " 'opposition',\n",
       " 'longer',\n",
       " 'products',\n",
       " 'remember',\n",
       " 'which',\n",
       " 'ministers',\n",
       " 'in',\n",
       " 'payments',\n",
       " 'their',\n",
       " 'system',\n",
       " 'going',\n",
       " 'advantage',\n",
       " 'way',\n",
       " 'moment',\n",
       " 've',\n",
       " '290',\n",
       " 'received',\n",
       " 'still',\n",
       " 'writing',\n",
       " 'back',\n",
       " 'agriculture',\n",
       " 'them',\n",
       " 'whether',\n",
       " 'though',\n",
       " 'thing',\n",
       " 'anything',\n",
       " 'jordanian',\n",
       " 'despite',\n",
       " 'preserve',\n",
       " 'inquiry',\n",
       " 'single',\n",
       " 'fair',\n",
       " 'be',\n",
       " 'after',\n",
       " 'andrew',\n",
       " 'said',\n",
       " 'kept',\n",
       " 'fully',\n",
       " 'colleagues',\n",
       " 'try',\n",
       " 'producer',\n",
       " 'email',\n",
       " 'overseas',\n",
       " 'foothold',\n",
       " 'middle',\n",
       " 'service',\n",
       " 'asian',\n",
       " 'plenty',\n",
       " 'could',\n",
       " 'everything',\n",
       " 'drop',\n",
       " 'an',\n",
       " 'contact',\n",
       " \"'\",\n",
       " 'iraqi',\n",
       " 'got',\n",
       " 'over',\n",
       " 'asking',\n",
       " 'revelations',\n",
       " 'letter',\n",
       " 'd',\n",
       " 'fairly',\n",
       " 'round',\n",
       " 'reading',\n",
       " 'much',\n",
       " 'trucking',\n",
       " 'give',\n",
       " 'reasonable',\n",
       " 'support',\n",
       " '<UNK>']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs  #checking vocab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size, word_sequence, win_size=2):\n",
    "\n",
    "    skip_grams = []\n",
    "\n",
    "    for sent in corpus_lower:\n",
    "        for i in range(1, len(sent) - 1): \n",
    "            target = word2index[sent[i]]\n",
    "            \n",
    "            context = []\n",
    "            \n",
    "            for j in range(2):\n",
    "                \n",
    "                if i - (j + 1) >= 0: \n",
    "                    context.append(word2index[sent[i - (j + 1)]])\n",
    "                \n",
    "                if i + (j + 1) < len(sent): \n",
    "                    context.append(word2index[sent[i + (j + 1)]])\n",
    "    \n",
    "            for w in context:\n",
    "                skip_grams.append([target, w])\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False)\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams[i][0]])  \n",
    "        random_labels.append([skip_grams[i][1]])  \n",
    "            \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        \n",
    "        #convert them into embedding\n",
    "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
    "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
    "        \n",
    "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
    "        \n",
    "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
    "         \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
    "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
    "        \n",
    "        return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 249])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing all_vocabs\n",
    "\n",
    "batch_size = 2\n",
    "voc_size = len(vocabs)\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    #map(function, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a9409b9deca2e32b1801514822bf60b5f36ee24c0efb3dea589c0a4c1325f8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
