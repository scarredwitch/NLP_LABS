{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do this:\n",
    "1. Compare them based on syntactic accuracy and semantic accuracy, similar to how is done in https://nlp.stanford.edu/pubs/glove.pdf (see Table 2) - NO NEED to try 1000 or 300 embed size.....I just want you to learn how to do experiment.....\n",
    "2. Try to find a correlation with just ONE similarity dataset (which humans judge how similar is two words.....)\n",
    "\n",
    "Point criteria:\n",
    "0:  Not done\n",
    "1: ok\n",
    "2: with comments / explanation / figures just like how Chaky explain thing....."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some suggestions for the assignment report:\n",
    "1. Write a brief conclusion on your findings at the end of the report.\n",
    "2. Clear long outputs in the notebook before submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to C:\\Users\\Sirikit\n",
      "[nltk_data]     Joshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#using real corpus from nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "corpus = nltk.corpus.brown.sents(categories=['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751\n"
     ]
    }
   ],
   "source": [
    "#let's check the size of the corpus\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['it', 'is', 'not', 'news', 'that', 'nathan', 'milstein', 'is', 'a', 'wizard', 'of', 'the', 'violin', '.'], ['certainly', 'not', 'in', 'orchestra', 'hall', 'where', 'he', 'has', 'played', 'countless', 'recitals', ',', 'and', 'where', 'thursday', 'night', 'he', 'celebrated', 'his', '20th', 'season', 'with', 'the', 'chicago', 'symphony', 'orchestra', ',', 'playing', 'the', 'brahms', 'concerto', 'with', 'his', 'own', 'slashing', ',', 'demon-ridden', 'cadenza', 'melting', 'into', 'the', 'high', ',', 'pale', ',', 'pure', 'and', 'lovely', 'song', 'with', 'which', 'a', 'violinist', 'unlocks', 'the', 'heart', 'of', 'the', 'music', ',', 'or', 'forever', 'finds', 'it', 'closed', '.'], ['there', 'was', 'about', 'that', 'song', 'something', 'incandescent', ',', 'for', 'this', 'brahms', 'was', 'milstein', 'at', 'white', 'heat', '.'], ['not', 'the', 'noblest', 'performance', 'we', 'have', 'heard', 'him', 'play', ',', 'or', 'the', 'most', 'spacious', ',', 'or', 'even', 'the', 'most', 'eloquent', '.'], ['those', 'would', 'be', 'reserved', 'for', 'the', \"orchestra's\", 'great', 'nights', 'when', 'the', 'soloist', 'can', 'surpass', 'himself', '.']]\n"
     ]
    }
   ],
   "source": [
    "#1. Tokenize\n",
    "corpus_tokenized = [[word.lower() for word in sent] for sent in corpus]\n",
    "print(corpus_tokenized[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'bruhn', 'closeup', 'allegory', 'recounting']\n"
     ]
    }
   ],
   "source": [
    "#2. numericalize\n",
    "\n",
    "#2.1 get all the unique words\n",
    "#we want to flatten this (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs  = list(set(flatten(corpus_tokenized)))  #vocabs is a term defining all unique words your system know\n",
    "print(vocabs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 assign id to all these vocabs\n",
    "word2index = {v: idx+1 for idx, v in enumerate(vocabs)}\n",
    "\n",
    "#add <UNK>, which is a very normal token exists in the world\n",
    "vocabs.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKKK, or anything\n",
    "\n",
    "word2index['<UNK>'] = 0 \n",
    "# word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create index2word dictionary\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "# index2word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Creating co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Co-occurence Matrix\n",
    "from collections import Counter\n",
    "\n",
    "X_i = Counter(flatten(corpus))\n",
    "# print(X_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating random_batch_skipgram\n",
    "def random_batch_skipgram(corpus, window_size = 1):\n",
    "    skip_grams = []\n",
    "    for sent in corpus:\n",
    "        for i in range(1, len(sent) - 1):\n",
    "            target = sent[i]\n",
    "            context = []\n",
    "            for j in range(window_size):\n",
    "                if i - (j + 1) >= 0:  ## Checking  if out of range from left of list\n",
    "                    context.append(sent[i - (j + 1)])\n",
    "                if i + (j + 1) < len(sent): \n",
    "                    context.append(sent[i + (j + 1)])\n",
    "            for w in context:\n",
    "                skip_grams.append((target,w))\n",
    "    return skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_grams = []\n",
    "cbows = []\n",
    "window_size = 2\n",
    "#for each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    for i in range(1,len(sent)-window_size): #start from 2 to second last\n",
    "        context_word = []\n",
    "        # print(sent[i])\n",
    "        center_word = sent[i]\n",
    "        for j in range(window_size):\n",
    "            outside_word = [sent[i-j-1],sent[i+j+1]] #window_size adjustable\n",
    "            #here we want to create (banana, apple), (banana, fruit) append to some list\n",
    "            for o in outside_word:\n",
    "                context_word.append(o)\n",
    "                skip_grams.append((center_word,o))\n",
    "            cbows.append((context_word,center_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding co-occurance in skip_grams with window size = 2\n",
    "X_ik_skipgram = Counter(random_batch_skipgram(corpus, window_size = 2))\n",
    "\n",
    "# print(X_ik_skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight function in order to scale down frequent words\n",
    "\n",
    "def weighting(w_i, w_j, X_ik):\n",
    "        \n",
    "    #check whether the co-occurrences exist between these two words\n",
    "    try:\n",
    "        x_ij = X_ik[(w_i, w_j)]\n",
    "    except:\n",
    "        x_ij = 1  #if does not exist, set it to 1\n",
    "                \n",
    "    x_max = 100 #100 # fixed in paper  #cannot exceed 100 counts\n",
    "    alpha = 0.75\n",
    "    \n",
    "    #if co-occurrence does not exceed 100, scale it based on some alpha\n",
    "    if x_ij < x_max:\n",
    "        result = (x_ij/x_max)**alpha  #scale it\n",
    "    else:\n",
    "        result = 1  #if is greater than max, set it to 1 maximum\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now apply this weighting to all possible pairs\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "X_ik = {}  #for keeping the co-occurences\n",
    "weighting_dic = {} #scaling the percentage of sampling\n",
    "\n",
    "for bigram in combinations_with_replacement(vocabs, 2):\n",
    "    if X_ik_skipgram.get(bigram) is not None:  #matches \n",
    "        cooc = X_ik_skipgram[bigram]  #get the count from what we already counted\n",
    "        X_ik[bigram] = cooc + 1 # + 1 for stability issue\n",
    "        X_ik[(bigram[1], bigram[0])] = cooc + 1   #count also for the opposite\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #apply the weighting function using this co-occurrence matrix thingy   \n",
    "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
    "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
    "\n",
    "    #removed printing to avoid crashing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing train data\n",
    "\n",
    "import math\n",
    "\n",
    "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
    "\n",
    "    #loop through skipgram, and change it id because when sending model, it must number \n",
    "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
    "    \n",
    "    #randomly pick 'batch_size' indexes\n",
    "    number_of_choices = len(skip_grams_id)\n",
    "    random_index = np.random.choice(number_of_choices, batch_size, replace=False) #no repeating indexes among  these random indexes\n",
    "    \n",
    "    random_inputs = [] #xi, wi (in batches)\n",
    "    random_labels = [] #xj, wj (in batches)\n",
    "    random_coocs  = [] #xij (in batches)\n",
    "    random_weighting = [] #f(xij) (in batches)\n",
    "    #for each of the sample in these indexes\n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams_id[i][0]]) #same reason why I put bracket here....\n",
    "        random_labels.append([skip_grams_id[i][1]])\n",
    "\n",
    "        #get coocs\n",
    "        #first check whether it exists.....\n",
    "        pair = skip_grams[i] #e.g., ['banana','fruit']\n",
    "        try:\n",
    "            cooc = X_ik[pair]\n",
    "        except:\n",
    "            cooc = 1 #label smoothing\n",
    "\n",
    "        random_coocs.append([math.log(cooc)]) #1. why log, #2 why bracket -> size ==> (,1) #my neural network excepts (,1)\n",
    "        \n",
    "        #for weighting\n",
    "        weighting = weighting_dic[pair] #why not user try... maybe it does not exist\n",
    "        random_weighting.append(weighting)\n",
    "\n",
    "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2854],\n",
       "        [1633]]),\n",
       " array([[ 126],\n",
       "        [1801]]),\n",
       " array([[2.7080502 ],\n",
       "        [0.69314718]]),\n",
       " array([0.24102853, 0.05318296]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input, target, cooc, weightin = random_batch(batch_size, corpus_tokenized, skip_grams, X_ik, weighting_dic)\n",
    "input, target, cooc, weightin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Glove Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size,embed_size):\n",
    "        super(GloVe,self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
    "        \n",
    "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
    "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
    "        \n",
    "    def forward(self, center_words, target_words, coocs, weighting):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        \n",
    "        center_bias = self.v_bias(center_words).squeeze(1)\n",
    "        target_bias = self.u_bias(target_words).squeeze(1)\n",
    "        \n",
    "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        #note that coocs already got log\n",
    "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
    "        \n",
    "        return torch.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size   = len(vocabs)\n",
    "batch_size = 2 \n",
    "emb_size   = 2 \n",
    "model      = GloVe(voc_size, emb_size)\n",
    "\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Loss: 0.263171 | Time: 40.35958695411682\n",
      "Epoch 2000 | Loss: 2.676057 | Time: 82.35004210472107\n",
      "Epoch 3000 | Loss: 0.508378 | Time: 124.43235373497009\n",
      "Epoch 4000 | Loss: 3.206538 | Time: 164.54973196983337\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 4000\n",
    "start = time.time()\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #get random batch\n",
    "    input, target, cooc, weightin = random_batch(batch_size, corpus_tokenized, skip_grams, X_ik, weighting_dic)\n",
    "    input_batch    = torch.LongTensor(input)\n",
    "    target_batch   = torch.LongTensor(target)\n",
    "    cooc_batch     = torch.FloatTensor(cooc)\n",
    "    weightin_batch = torch.FloatTensor(weightin)\n",
    "    \n",
    "    \n",
    "    # print(input_batch.shape, label_batch.shape, cooc_batch.shape, weightin_batch)\n",
    "    \n",
    "    #loss = model\n",
    "    loss = model(input_batch, target_batch, cooc_batch, weightin_batch)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        end = time.time()\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: {(end-start)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to get embedding\n",
    "def get_embed(word, current_model=model):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except :\n",
    "        index = word2index['<UNK>'] #unknown\n",
    "    word = torch.LongTensor([index])\n",
    "    \n",
    "    embed =  (current_model.embedding_v(word)+current_model.embedding_u(word))/2\n",
    "    return np.array(embed[0].detach().numpy())\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.title('Window size of 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "torch.save(model.state_dict(), \"Glove_Model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def cosine_similarity(word1, word2):\n",
    "    '''\n",
    "        cosine_similarity function accepts the embeddings of two words and returns the \n",
    "        the degree of similarity between them using scipy.\n",
    "    '''\n",
    "    cos_sim = 1 - spatial.distance.cosine(word1, word2)  #distance = 1 - similarlity, because scipy only gives distance\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adultery vs loose:  0.9278067350387573\n",
      "loose vs pillow:  -0.8149043321609497\n"
     ]
    }
   ],
   "source": [
    "#getting cosine similarity\n",
    "adultery = get_embed('adultery')\n",
    "loose = get_embed('loose')\n",
    "pillow = get_embed('pillow')\n",
    "\n",
    "print(f\"adultery vs loose: \", cosine_similarity(adultery, loose))\n",
    "print(f\"loose vs pillow: \", cosine_similarity(loose, pillow))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[': capital-common-countries\\n', 'Athens Greece Baghdad Iraq\\n', 'Athens Greece Bangkok Thailand\\n', 'Athens Greece Beijing China\\n', 'Athens Greece Berlin Germany\\n', 'Athens Greece Bern Switzerland\\n', 'Athens Greece Cairo Egypt\\n', 'Athens Greece Canberra Australia\\n', 'Athens Greece Hanoi Vietnam\\n', 'Athens Greece Havana Cuba\\n']\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "file =  open('../SIRI_code_along/Data/questions-words.txt', mode='r')\n",
    "question_words = []\n",
    "for content in file:\n",
    "  question_words.append(content)\n",
    "\n",
    "print(question_words[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    '''\n",
    "        Skipgram implementation \n",
    "        class that accepts the parameter vocabulary\n",
    "        size and embedding size\n",
    "    '''\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  \n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        center_word_embed  = self.embedding_center_word(center_word)     \n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)  \n",
    "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)    \n",
    "        \n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "        \n",
    "        top_term_exp = torch.exp(top_term) \n",
    "        \n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)         \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1)\n",
    "        \n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
    "        \n",
    "        return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramNegSampling(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super(SkipgramNegSampling, self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size) # out embedding\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "                    \n",
    "    def forward(self, center_words, target_words, negative_words):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        neg_embeds    = -self.embedding_u(negative_words) # [batch_size, num_neg, emb_size]\n",
    "        \n",
    "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        negative_score = neg_embeds.bmm(center_embeds.transpose(1, 2))\n",
    "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1]\n",
    "        \n",
    "        loss = self.logsigmoid(positive_score) + torch.sum(self.logsigmoid(negative_score), 1)\n",
    "                \n",
    "        return -torch.mean(loss)\n",
    "    \n",
    "    def prediction(self, inputs):\n",
    "        embeds = self.embedding_v(inputs)\n",
    "        \n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    ''' Continuous Bag of words implementation \n",
    "        class that accepts the parameter vocabulary\n",
    "        size and embedding size'''\n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  \n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        center_word_embed  = self.embedding_center_word(center_word)     \n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)  \n",
    "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)    \n",
    "        \n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "        \n",
    "        top_term_exp = torch.exp(top_term) \n",
    "        \n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)         \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1)\n",
    "        \n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
    "        \n",
    "        return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ': capital-common-countries\\n'),\n",
       " (507, ': capital-world\\n'),\n",
       " (5032, ': currency\\n'),\n",
       " (5899, ': city-in-state\\n'),\n",
       " (8367, ': family\\n'),\n",
       " (8874, ': gram1-adjective-to-adverb\\n'),\n",
       " (9867, ': gram2-opposite\\n'),\n",
       " (10680, ': gram3-comparative\\n'),\n",
       " (12013, ': gram4-superlative\\n'),\n",
       " (13136, ': gram5-present-participle\\n'),\n",
       " (14193, ': gram6-nationality-adjective\\n'),\n",
       " (15793, ': gram7-past-tense\\n'),\n",
       " (17354, ': gram8-plural\\n'),\n",
       " (18687, ': gram9-plural-verbs\\n')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate header name and index\n",
    "separator = [(idx, sent) for idx, sent in enumerate(question_words) if sent[0] == ':']\n",
    "separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjective_to_adverb = question_words[8875:9867]\n",
    "comparative         = question_words[10681:12013]\n",
    "nationality         = question_words[14194:15793]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing amazingly apparent apparently\\n', 'amazing amazingly calm calmly\\n', 'amazing amazingly cheerful cheerfully\\n', 'amazing amazingly complete completely\\n', 'amazing amazingly efficient efficiently\\n'] \n",
      "\n",
      "['bad worse big bigger\\n', 'bad worse bright brighter\\n', 'bad worse cheap cheaper\\n', 'bad worse cold colder\\n', 'bad worse cool cooler\\n'] \n",
      "\n",
      "['Albania Albanian Argentina Argentinean\\n', 'Albania Albanian Australia Australian\\n', 'Albania Albanian Austria Austrian\\n', 'Albania Albanian Belarus Belorussian\\n', 'Albania Albanian Brazil Brazilian\\n'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(adjective_to_adverb[0:5], \"\\n\")\n",
    "print(comparative[0:5], \"\\n\")\n",
    "print(nationality[0:5], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = adjective_to_adverb + comparative + nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adj_to_adv = [sentence.split(\" \") for sentence in adjective_to_adverb]\n",
    "test_comparative = [sentence.split(\" \") for sentence in comparative]\n",
    "test_nation = [sentence.split(\" \") for sentence in nationality]\n",
    "test_set = [sentence.split(\" \") for sentence in test_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['amazing', 'amazingly', 'apparent', 'apparently\\n'], ['amazing', 'amazingly', 'calm', 'calmly\\n'], ['amazing', 'amazingly', 'cheerful', 'cheerfully\\n'], ['amazing', 'amazingly', 'complete', 'completely\\n'], ['amazing', 'amazingly', 'efficient', 'efficiently\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(test_set[0:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Flatten and get unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quiet',\n",
       " 'stronger\\n',\n",
       " 'Dutch',\n",
       " 'Netherlands',\n",
       " 'Swedish',\n",
       " 'faster\\n',\n",
       " 'seriously\\n',\n",
       " 'tighter',\n",
       " 'furiously\\n',\n",
       " 'louder\\n']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "test_vocab = list(set(flatten(test_set)))\n",
    "test_vocab[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word2index = dict()\n",
    "test_word2index.update({\"\":  0})\n",
    "for idx, v in enumerate(test_vocab):\n",
    "        test_word2index.update({v:  idx + 1})\n",
    "\n",
    "test_vocab.append('')\n",
    "\n",
    "test_index2word = {v:k for k, v in test_word2index.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Semantic Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy(a,b,c,current_model, vocabs=vocabs):\n",
    "    emb_a, emb_b, emb_c = get_embed(a, current_model), get_embed(b, current_model), get_embed(c, current_model)\n",
    "    vector = emb_b - emb_a + emb_c\n",
    "    similarity = -1 \n",
    "    \n",
    "    for vocab in vocabs:\n",
    "        if vocab not in [a,b,c]: #ignore input words itself\n",
    "            current_sim = cosine_similarity(vector,get_embed(vocab, current_model))\n",
    "            if current_sim > similarity:\n",
    "                similarity = current_sim #update better one\n",
    "                d = (vocab, similarity)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dora', 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_analogy('amazing','amazingly','apparent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(y, yhat):\n",
    "    if y == yhat:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def test_accuracy_batch(data, current_model):\n",
    "    counter = 0\n",
    "    for sent in data:\n",
    "        label = sent[-1]\n",
    "        a, b, c = sent[:-1]\n",
    "        yhat = find_analogy(a, b, c, current_model)[0] # It's return in tuple form, so we need to slice to get word\n",
    "        if check_accuracy(label, yhat) == True:\n",
    "            counter = counter + 1\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (embedding_center_word): Embedding(8070, 2)\n",
       "  (embedding_outside_word): Embedding(8070, 2)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load skipgram_model\n",
    "skipgram_model = Skipgram(voc_size, embedding_size)\n",
    "torch.save(skipgram_model.state_dict(), \"SkipgramsModel.pth\")\n",
    "skipgram_model.load_state_dict(torch.load('SkipgramsModel.pth'))\n",
    "skipgram_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkipgramNegSampling(\n",
       "  (embedding_v): Embedding(8070, 2)\n",
       "  (embedding_u): Embedding(8070, 2)\n",
       "  (logsigmoid): LogSigmoid()\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load negative skipgram model\n",
    "neg_skipgram_model = SkipgramNegSampling(voc_size, embedding_size)\n",
    "torch.save(neg_skipgram_model.state_dict(), \"Neg_SkipgramsModel.pth\")\n",
    "neg_skipgram_model.load_state_dict(torch.load('Neg_SkipgramsModel.pth'))\n",
    "neg_skipgram_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CBOW(\n",
       "  (embedding_center_word): Embedding(8070, 2)\n",
       "  (embedding_outside_word): Embedding(8070, 2)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load cbow model\n",
    "cbow_model = CBOW(voc_size, embedding_size)\n",
    "torch.save(cbow_model.state_dict(), \"Cbow_Model.pth\")\n",
    "cbow_model.load_state_dict(torch.load('Cbow_Model.pth'))\n",
    "cbow_model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 For Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current_test = test_adj_to_adv\n",
      "0\n",
      "Current_test = test_comparative\n",
      "0\n",
      "Current_test = test_nation\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "current_model = GloVe(voc_size, embedding_size)\n",
    "current_model.load_state_dict(torch.load('Glove_Model.pth'))\n",
    "current_model.eval()\n",
    "\n",
    "test_list = [test_adj_to_adv, test_comparative, test_nation]\n",
    "test_list_name = ['test_adj_to_adv','test_comparative', 'test_nation']\n",
    "\n",
    "for idx, current_test in enumerate(test_list):\n",
    "   sample_list = random.choices(current_test, k=100)\n",
    "   print(f'Current_test = {test_list_name[idx]}')\n",
    "   accuracy = test_accuracy_batch(sample_list, current_model)\n",
    "   print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 For Skipgram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current_test = test_adj_to_adv\n",
      "0\n",
      "Current_test = test_comparative\n",
      "0\n",
      "Current_test = test_nation\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 2\n",
    "\n",
    "current_model = Skipgram(voc_size, embedding_size)\n",
    "current_model.load_state_dict(torch.load('SkipgramsModel.pth'))\n",
    "current_model.eval()\n",
    "\n",
    "test_list = [test_adj_to_adv, test_comparative, test_nation]\n",
    "test_list_name = ['test_adj_to_adv','test_comparative', 'test_nation']\n",
    "\n",
    "for idx, current_test in enumerate(test_list):\n",
    "   sample_list = random.choices(current_test, k=100)\n",
    "   print(f'Current_test = {test_list_name[idx]}')\n",
    "   accuracy = test_accuracy_batch(sample_list, current_model)\n",
    "   print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 For CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 2\n",
    "\n",
    "current_model = CBOW(voc_size, embedding_size)\n",
    "current_model.load_state_dict(torch.load('Cbow_Model.pth'))\n",
    "current_model.eval()\n",
    "\n",
    "test_list = [test_adj_to_adv, test_comparative, test_nation]\n",
    "test_list_name = ['test_adj_to_adv','test_comparative', 'test_nation']\n",
    "\n",
    "for idx, current_test in enumerate(test_list):\n",
    "   sample_list = random.choices(current_test, k=100)\n",
    "   print(f'Current_test = {test_list_name[idx]}')\n",
    "   accuracy = test_accuracy_batch(sample_list, current_model)\n",
    "   print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 For Skipgram with Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Override get embed for negative sampling due to embedding name change\n",
    "def get_embed(word):\n",
    "    id_tensor = torch.LongTensor([word2index[word]])\n",
    "    v_embed = model.embedding_v(id_tensor)\n",
    "    u_embed = model.embedding_u(id_tensor) \n",
    "    word_embed = (v_embed + u_embed) / 2 \n",
    "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word, current_model):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except :\n",
    "        index = word2index['<UNK>'] #unknown\n",
    "    word = torch.LongTensor([index])\n",
    "    \n",
    "    embed =  (current_model.embedding_v(word)+ current_model.embedding_u(word))/2\n",
    "    return np.array(embed[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current_test = test_adj_to_adv\n",
      "0\n",
      "Current_test = test_comparative\n",
      "0\n",
      "Current_test = test_nation\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 2\n",
    "\n",
    "current_model = SkipgramNegSampling(voc_size, embedding_size)\n",
    "current_model.load_state_dict(torch.load('Neg_SkipgramsModel.pth'))\n",
    "current_model.eval()\n",
    "\n",
    "test_list = [test_adj_to_adv, test_comparative, test_nation]\n",
    "test_list_name = ['test_adj_to_adv','test_comparative', 'test_nation']\n",
    "\n",
    "for idx, current_test in enumerate(test_list):\n",
    "   sample_list = random.choices(current_test, k=100)\n",
    "   print(f'Current_test = {test_list_name[idx]}')\n",
    "   accuracy = test_accuracy_batch(sample_list, current_model)\n",
    "   print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Syntactic Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plane</td>\n",
       "      <td>car</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>car</td>\n",
       "      <td>6.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>television</td>\n",
       "      <td>radio</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2\n",
       "0       tiger    cat   7.35\n",
       "1       tiger  tiger  10.00\n",
       "2       plane    car   5.77\n",
       "3       train    car   6.31\n",
       "4  television  radio   6.77"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = '../SIRI_code_along/Data/wordsim353_sim_rel/wordsim_similarity_goldstandard.txt'\n",
    "df = pd.read_table(path, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plane</td>\n",
       "      <td>car</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>car</td>\n",
       "      <td>6.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>television</td>\n",
       "      <td>radio</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2\n",
       "0       tiger    cat   7.35\n",
       "1       tiger  tiger  10.00\n",
       "2       plane    car   5.77\n",
       "3       train    car   6.31\n",
       "4  television  radio   6.77"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sytactic_test_set = df.iloc[:20]\n",
    "sytactic_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = sytactic_test_set[0]\n",
    "x2 = sytactic_test_set[1]\n",
    "label = sytactic_test_set[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "embedding_size=2\n",
    "model = GloVe(voc_size, embedding_size)\n",
    "model.load_state_dict(torch.load('Glove_Model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_list = [test_adj_to_adv, test_comparative, test_nation]\n",
    "test_list_name = ['test_adj_to_adv', 'test_comparative', 'test_nation']\n",
    "\n",
    "results = []\n",
    "for idx in range(20): # We test with only fix 10 samples\n",
    "    emb_x1 = get_embed(x1[idx], model)\n",
    "    emb_x2 = get_embed(x2[idx], model)\n",
    "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
    "    yhat = yhat[0]\n",
    "    results.append(yhat)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Skipgram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word, current_model):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except :\n",
    "        index = word2index['<UNK>'] #unknown\n",
    "    word = torch.LongTensor([index])\n",
    "    \n",
    "    embed =  (current_model.embedding_center_word(word)+current_model.embedding_outside_word (word))/2\n",
    "    return np.array(embed[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = skipgram_model\n",
    "\n",
    "test_list = [test_adj_to_adv, test_comparative, test_nation]\n",
    "test_list_name = ['test_adj_to_adv', 'test_comparative', 'test_nation']\n",
    "\n",
    "results = []\n",
    "for idx in range(20):\n",
    "    emb_x1 = get_embed(x1[idx], model)\n",
    "    emb_x2 = get_embed(x2[idx], model)\n",
    "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
    "    yhat = yhat[0]\n",
    "    results.append(yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cbow_model\n",
    "\n",
    "test_list = [test_adj_to_adv, test_comparative, test_nation]\n",
    "test_list_name = ['test_adj_to_adv', 'test_comparative', 'test_nation']\n",
    "\n",
    "results = []\n",
    "for idx in range(20): \n",
    "    emb_x1 = get_embed(x1[idx], model)\n",
    "    emb_x2 = get_embed(x2[idx], model)\n",
    "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
    "    yhat = yhat[0]\n",
    "    results.append(yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Skipgram with Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word, current_model):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except :\n",
    "        index = word2index['<UNK>'] #unknown\n",
    "    word = torch.LongTensor([index])\n",
    "    \n",
    "    embed =  (current_model.embedding_v(word)+current_model.embedding_u(word))/2\n",
    "    return np.array(embed[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neg_skipgram_model\n",
    "\n",
    "test_list = [test_adj_to_adv, test_comparative, test_nation]\n",
    "test_list_name = ['test_adj_to_adv', 'test_comparative', 'test_nation']\n",
    "\n",
    "results = []\n",
    "for idx in range(20): \n",
    "    emb_x1 = get_embed(x1[idx], model)\n",
    "    emb_x2 = get_embed(x2[idx], model)\n",
    "    yhat = stats.spearmanr(emb_x1, emb_x2)\n",
    "    yhat = yhat[0]\n",
    "    results.append(yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "All the results come out to 0. This could be because the training dataset was very small. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a9409b9deca2e32b1801514822bf60b5f36ee24c0efb3dea589c0a4c1325f8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
