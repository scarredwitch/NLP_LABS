{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4tCf4WiIjld",
        "outputId": "eb0ee4b1-bb1e-4b9b-f790-e4b3201e5297"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sirikit Joshi\\.conda\\envs\\cudaenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch, torchdata, torchtext\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random, math, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NVIDIA GeForce RTX 3060 Laptop GPU'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wqe2EUGEIpdK",
        "outputId": "5e9ce1fe-bff7-4371-e777-112640ac90df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>english</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>रन</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Run</td>\n",
              "      <td>NaN</td>\n",
              "      <td>रन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Run</td>\n",
              "      <td>NaN</td>\n",
              "      <td>रन</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Wow</td>\n",
              "      <td>NaN</td>\n",
              "      <td>वाह</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Fire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>आगो</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Help</td>\n",
              "      <td>NaN</td>\n",
              "      <td>सहायता</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136836</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136837</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136838</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136839</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136840</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136841 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0 english  Unnamed: 2      रन\n",
              "0              0.0     Run         NaN      रन\n",
              "1              1.0     Run         NaN      रन\n",
              "2              2.0     Wow         NaN     वाह\n",
              "3              3.0    Fire         NaN     आगो\n",
              "4              4.0    Help         NaN  सहायता\n",
              "...            ...     ...         ...     ...\n",
              "136836         NaN     NaN         NaN     NaN\n",
              "136837         NaN     NaN         NaN     NaN\n",
              "136838         NaN     NaN         NaN     NaN\n",
              "136839         NaN     NaN         NaN     NaN\n",
              "136840         NaN     NaN         NaN     NaN\n",
              "\n",
              "[136841 rows x 4 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data_raw = pd.read_csv(\"./dataset/translation.csv\")\n",
        "data_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZulA1v6kI2v-",
        "outputId": "7394a8fd-97aa-4bad-835e-af8ff88a3ef8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>english</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>रन</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Unnamed: 0, english, Unnamed: 2, रन]\n",
              "Index: []"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_raw.dropna(inplace=True)\n",
        "data_raw.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JreAcX2PMQfo"
      },
      "source": [
        "#2. EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00TBSMMfMC3i",
        "outputId": "c3dd0c31-3f27-44c8-fdf2-646959921573"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = data_raw.values.tolist()\n",
        "dataset_size = len(dataset)\n",
        "dataset_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z5eHM_-sMX6n"
      },
      "outputs": [],
      "source": [
        "random.shuffle(dataset)\n",
        "train_data_set_size = int(dataset_size *0.9)\n",
        "\n",
        "train_dataset = dataset[:train_data_set_size]\n",
        "test = dataset[train_data_set_size:]\n",
        "\n",
        "train_size = int(train_data_set_size *0.9)\n",
        "train = train_dataset[:train_size]\n",
        "val = train_dataset[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ-qNFGXMf2c",
        "outputId": "d672bcb5-db44-4026-d4b1-d5369ced1e26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 0, 0)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train),len(val),len(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnrUd1fHMjvi"
      },
      "source": [
        "#3.Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SUREjzMTMiMt"
      },
      "outputs": [],
      "source": [
        "SRC_LANGUAGE = 'np'\n",
        "TRG_LANGUAGE = 'en'\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eX5pS_DsMu5b"
      },
      "outputs": [],
      "source": [
        "from attacut import tokenize, Tokenizer\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "token_transform[SRC_LANGUAGE] = Tokenizer(model=\"attacut-sc\")\n",
        "token_transform[TRG_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svh2TM5qM3nD",
        "outputId": "5680b79c-5e41-4a3b-bd1c-d2deeaec4833"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Sirikit Joshi\\Documents\\SIRI\\NLP\\NLP_LABS\\Coding Assignment\\English_Nepali_Translation\\English_Nepali_Translation.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sirikit%20Joshi/Documents/SIRI/NLP/NLP_LABS/Coding%20Assignment/English_Nepali_Translation/English_Nepali_Translation.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#example of tokenization of the nepali part\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sirikit%20Joshi/Documents/SIRI/NLP/NLP_LABS/Coding%20Assignment/English_Nepali_Translation/English_Nepali_Translation.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSentence: \u001b[39m\u001b[39m\"\u001b[39m, train[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sirikit%20Joshi/Documents/SIRI/NLP/NLP_LABS/Coding%20Assignment/English_Nepali_Translation/English_Nepali_Translation.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTokenization: \u001b[39m\u001b[39m\"\u001b[39m, token_transform[SRC_LANGUAGE]\u001b[39m.\u001b[39mtokenize(train[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]))\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "#example of tokenization of the nepali part\n",
        "print(\"Sentence: \", train[0][1])\n",
        "print(\"Tokenization: \", token_transform[SRC_LANGUAGE].tokenize(train[0][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHFpI7fWNG_I",
        "outputId": "4bd4bfda-3baf-4108-8113-847d2a2096a7"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mg:\\Other computers\\My Laptop\\Thailand\\2nd Semester\\NLP\\CODING\\SIRI_code_along\\HW\\Nepali-English-Translation\\nepali_english_translate.ipynb Cell 12\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#example of tokenization of the english part\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSentence: \u001b[39m\u001b[39m\"\u001b[39m, train[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTokenization: \u001b[39m\u001b[39m\"\u001b[39m, token_transform[SRC_LANGUAGE]\u001b[39m.\u001b[39mtokenize(train[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]))\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "#example of tokenization of the english part\n",
        "print(\"Sentence: \", train[0][0])\n",
        "print(\"Tokenization: \", token_transform[SRC_LANGUAGE].tokenize(train[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5qlzDoINR10"
      },
      "outputs": [],
      "source": [
        "# helper function to yield list of tokens\n",
        "# here data can be `train` or `val` or `test`\n",
        "def yield_tokens(data, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TRG_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data:\n",
        "        if language == SRC_LANGUAGE:\n",
        "            yield token_transform[language].tokenize(data_sample[language_index[language]])\n",
        "        elif language == TRG_LANGUAGE:\n",
        "            yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_4dOSgrNYvC"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    # Create torchtext's Vocab object \n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train, ln), \n",
        "                                                    min_freq=2,   #if not, everything will be treated as UNK\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True) #indicates whether to insert symbols at the beginning or at the end                                            \n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glOjuAaoc4Fe"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('vocab.pkl', 'wb') as file:\n",
        "      \n",
        "    # A new file will be created\n",
        "    pickle.dump(vocab_transform, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ncYCAhddSxp"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('nepali_vocab.pkl', 'wb') as file:\n",
        "      \n",
        "    # A new file will be created\n",
        "    pickle.dump(vocab_transform[TRG_LANGUAGE], file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEj5l4fGOUpZ",
        "outputId": "186fc254-f2e3-47b1-cc4a-d0d4f917b76b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_transform[SRC_LANGUAGE](['here', 'is', 'a', 'unknownword', 'a'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6RvSktDPbiP",
        "outputId": "a6559b40-a2cf-450d-959d-feb5cb1ceff7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0, 0]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_transform[TRG_LANGUAGE](['उहाँले', 'एक', 'हो '])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "riozcqOdPodF",
        "outputId": "4f2228ad-dc2e-4460-d310-563e8c93cadc"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mg:\\Other computers\\My Laptop\\Thailand\\2nd Semester\\NLP\\CODING\\SIRI_code_along\\HW\\Nepali-English-Translation\\nepali_english_translate.ipynb Cell 19\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mapping \u001b[39m=\u001b[39m vocab_transform[TRG_LANGUAGE]\u001b[39m.\u001b[39mget_itos()\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# #print 1816, for example\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mapping[\u001b[39m400\u001b[39m]\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "#we can reverse its English....\n",
        "mapping = vocab_transform[TRG_LANGUAGE].get_itos()\n",
        "# #print 1816, for example\n",
        "mapping[400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K8hf176HPtKb",
        "outputId": "2d9b94f0-ba75-4766-8c88-016601681343"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' has'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#we can reverse its Thailand....\n",
        "mapping = vocab_transform[SRC_LANGUAGE].get_itos()\n",
        "# #print 1816, for example\n",
        "mapping[400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNTQVe73Pv_e",
        "outputId": "395d5974-ae5f-40dd-e2e7-3d80671948b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('<pad>', '<sos>', '<eos>')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mapping[1], mapping[2], mapping[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX1YERYRP4Nt"
      },
      "source": [
        "#4. Preparing the dataloader\n",
        "One thing we change here is the <B>collate_fn</B> which now also returns the length of sentence. This is required for <B>packed_padded_sequence</B>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN49gVOhP0ab"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "import multiprocessing as mp\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    global func\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            if transform == token_transform[SRC_LANGUAGE]:\n",
        "                txt_input = transform.tokenize(txt_input)\n",
        "            else:\n",
        "                txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([SOS_IDX]), \n",
        "                      torch.tensor(token_ids), \n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and trg language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TRG_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_batch(batch):\n",
        "    src_batch, src_len_batch, trg_batch = [], [], []\n",
        "    for src_sample, trg_sample in batch:\n",
        "        processed_text = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_batch.append(processed_text)\n",
        "        trg_batch.append(text_transform[TRG_LANGUAGE](trg_sample.rstrip(\"\\n\")))\n",
        "        src_len_batch.append(processed_text.size(0))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=PAD_IDX)\n",
        "    import pickle\n",
        "        \n",
        "    return src_batch, torch.tensor(src_len_batch, dtype=torch.int64), trg_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANIbHEonQQwh",
        "outputId": "f1a723eb-0966-4283-adb3-c9e8a888c998"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'np': <function __main__.func(txt_input)>,\n",
              " 'en': <function __main__.func(txt_input)>}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_transform\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUkRrC7WQUPF"
      },
      "source": [
        "#Create train, val, and test dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmrinHrBQTQ5"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mg:\\Other computers\\My Laptop\\Thailand\\2nd Semester\\NLP\\CODING\\SIRI_code_along\\HW\\Nepali-English-Translation\\nepali_english_translate.ipynb Cell 26\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train, batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                               shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, collate_fn\u001b[39m=\u001b[39mcollate_batch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m valid_loader \u001b[39m=\u001b[39m DataLoader(val, batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                               shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, collate_fn\u001b[39m=\u001b[39mcollate_batch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m test_loader  \u001b[39m=\u001b[39m DataLoader(test, batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Other%20computers/My%20Laptop/Thailand/2nd%20Semester/NLP/CODING/SIRI_code_along/HW/Nepali-English-Translation/nepali_english_translate.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                              shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, collate_fn\u001b[39m=\u001b[39mcollate_batch)\n",
            "File \u001b[1;32mc:\\Users\\Sirikit Joshi\\.conda\\envs\\cudaenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 344\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Sirikit Joshi\\.conda\\envs\\cudaenv\\lib\\site-packages\\torch\\utils\\data\\sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
            "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(val, batch_size=batch_size,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_loader  = DataLoader(test, batch_size=batch_size,\n",
        "                             shuffle=True, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3Ju_pM7QYYK"
      },
      "outputs": [],
      "source": [
        "for np, _, en in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVHP0DlMQjqF",
        "outputId": "2800f021-b42e-42c9-af5a-63bfee8e91f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nepali shape:  torch.Size([16, 32])\n",
            "English shape:  torch.Size([9, 32])\n"
          ]
        }
      ],
      "source": [
        "print(\"nepali shape: \", np.shape)  # (seq len, batch_size)\n",
        "print(\"English shape: \", en.shape)   # (seq len, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g13Es-3jQx1y"
      },
      "outputs": [],
      "source": [
        "train_loader_length = len(list(iter(train_loader)))\n",
        "val_loader_length   = len(list(iter(valid_loader)))\n",
        "test_loader_length  = len(list(iter(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixutooKJQ0jT",
        "outputId": "7be8073f-5829-45ea-86fa-dc1d9d4b930b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2604\n",
            "290\n",
            "322\n"
          ]
        }
      ],
      "source": [
        "print(train_loader_length)\n",
        "print(val_loader_length)\n",
        "print(test_loader_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCMCo7qQQpki"
      },
      "outputs": [],
      "source": [
        "train_loader_length = 3439\n",
        "val_loader_length = 383\n",
        "test_loader_length = 425"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjNw-hBkSRCC",
        "outputId": "713fe412-113b-4430-82ca-2273393c28e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3439, 383, 425)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loader_length, val_loader_length, test_loader_length  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng9pxRx-SUJS"
      },
      "source": [
        "#5. Design the model\n",
        "##Encoder\n",
        "The changes here all within the forward method. It now accepts the lengths of the source sentences as well as the sentences themselves.\n",
        "\n",
        "After the source sentence (padded automatically within the iterator) has been embedded, we can then use pack_padded_sequence on it with the lengths of the sentences. Note that the tensor containing the lengths of the sequences must be a CPU tensor as of the latest version of PyTorch, which we explicitly do so with to('cpu'). packed_embedded will then be our packed padded sequence. This can be then fed to our RNN as normal which will return packed_outputs, a packed tensor containing all of the hidden states from the sequence, and hidden which is simply the final hidden state from our sequence. hidden is a standard tensor and not packed in any way, the only difference is that as the input was a packed sequence, this tensor is from the final non-padded element in the sequence.\n",
        "\n",
        "We then unpack our packed_outputs using pad_packed_sequence which returns the outputs and the lengths of each, which we don't need.\n",
        "\n",
        "The first dimension of outputs is the padded sequence lengths however due to using a packed padded sequence the values of tensors when a padding token was the input will be all zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWjBi-MlSSvv"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn       = nn.GRU(emb_dim, hid_dim, bidirectional=True)\n",
        "        self.fc        = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.dropout   = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src: [src len, batch size]\n",
        "        #src len: [batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, \n",
        "                            src_len.to('cpu'), enforce_sorted=False)\n",
        "        \n",
        "        #packed_outputs contain all hidden states including padding guy\n",
        "        #hidden contains the last hidden states of the non-padded guys\n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "        #hidden: [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #convert packed_outputs to the guy that does not contain hidden states for padding\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
        "        #outputs: [src len, batch size, hid dim * num directions]\n",
        "        \n",
        "        #take the last hidden states from backward and forward\n",
        "        #hidden: (f, b, f, b)\n",
        "        forward  = hidden[-2, :, :]  #[batch size, hid dim]\n",
        "        backward = hidden[-1, :, :]  #[batch size, hid dim]\n",
        "        \n",
        "        hidden = torch.tanh(self.fc(torch.cat((forward, backward), dim = 1))) \n",
        "        #hidden: [batch size, hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft2ZIs3pSgdy"
      },
      "source": [
        "#Attention\n",
        "The attention used here is additive attention which is defined by:\n",
        "\n",
        "Previously, we allowed this module to \"pay attention\" to padding tokens within the source sentence. However, using masking, we can force the attention to only be over non-padding elements.\n",
        "\n",
        "The forward method now takes a mask input. This is a [batch size, source sentence length] tensor that is 1 when the source sentence token is not a padding token, and 0 when it is a padding token. For example, if the source sentence is: [\"hello\", \"how\", \"are\", \"you\", \"?\",,], then the mask would be [1, 1, 1, 1, 1, 0, 0].\n",
        "\n",
        "We apply the mask after the attention has been calculated, but before it has been normalized by the softmax function. It is applied using masked_fill. This fills the tensor at each element where the first argument (mask == 0) is true, with the value given by the second argument (-1e10). In other words, it will take the un-normalized attention values, and change the attention values over padded elements to be -1e10. As these numbers will be miniscule compared to the other values they will become zero when passed through the softmax layer, ensuring no attention is payed to padding tokens in the source sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTLChiynSeV2"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim, variants):\n",
        "        super().__init__()\n",
        "        self.variants = variants\n",
        "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
        "        self.W = nn.Linear(hid_dim,     hid_dim) #for decoder\n",
        "        self.U = nn.Linear(hid_dim * 2, hid_dim) #for encoder outputs\n",
        "                \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, hid dim]\n",
        "        #encoder_outputs = [src len, batch size, hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        #encoder_outputs = [batch size, src len, hid dim * 2]\n",
        "\n",
        "        if self.variants == 'additive': #work\n",
        "            #repeat decoder hidden state src_len times\n",
        "            hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "            #hidden = [batch size, src len, hid dim]\n",
        "            \n",
        "            energy = torch.tanh(self.W(hidden) + self.U(encoder_outputs))\n",
        "            #energy = [batch size, src len, hid dim]\n",
        "            \n",
        "            attention = self.v(energy).squeeze(2)\n",
        "            #attention = [batch size, src len]\n",
        "            \n",
        "        elif self.variants == 'general': #work\n",
        "            hidden = hidden.unsqueeze(1).repeat(1, 1, 2)\n",
        "            #hidden = [batch size, 1, hid dim*2]\n",
        "            #encoder_outputs = [batch size, hid dim * 2, src len]\n",
        "\n",
        "            energy = torch.bmm(hidden, encoder_outputs.transpose(1, 2))\n",
        "            attention = energy.squeeze(1)\n",
        "            #attention = [batch size, src len]\n",
        "\n",
        "        elif self.variants == 'multiplicative':\n",
        "            wh = self.W(hidden).unsqueeze(1).repeat(1, 1, 2)\n",
        "            #wh = [batch size, 1, hid dim*2]\n",
        "            #encoder_outputs = [batch size, hid dim * 2, src len]\n",
        "\n",
        "            energy = torch.bmm(wh, encoder_outputs.transpose(1, 2))\n",
        "            attention = energy.squeeze(1)\n",
        "\n",
        "        #use masked_fill_ if you want in-place\n",
        "        attention = attention.masked_fill(mask, -1e10)\n",
        "        #attention = [batch size, src len]\n",
        "        return F.softmax(attention, dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7MeUzk6SoEY",
        "outputId": "909e15b7-db8e-4a47-fa02-dcf2e3636d24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[           9, -10000000000,            7,            2, -10000000000,\n",
            "         -10000000000],\n",
            "        [          99, -10000000000, -10000000000,            0,            8,\n",
            "                    9]])\n"
          ]
        }
      ],
      "source": [
        "#example of masked_fill\n",
        "#reall that 1 is pad_idx\n",
        "x = torch.tensor([ [9, 1, 7, 2, 1, 1], [99, 1, 1, 0, 8, 9] ])\n",
        "\n",
        "mask = (x == PAD_IDX)\n",
        "\n",
        "x.masked_fill_(mask, -1e10)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0HmcvHkSsrX"
      },
      "source": [
        "#Decoder\n",
        "The decoder only needs a few small changes. It needs to accept a mask over the source sentence and pass this to the attention module. As we want to view the values of attention during inference, we also return the attention tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTESBAiLSqFw"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.gru = nn.GRU((hid_dim * 2) + emb_dim, hid_dim)\n",
        "        self.fc = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, hid dim]\n",
        "        #encoder_outputs = [src len, batch size, hid dim * 2]\n",
        "        #mask = [batch size, src len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "        #a = [batch size, src len]\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        #encoder_outputs = [batch size, src len, hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs) #Ct\n",
        "        #weighted = [batch size, 1, hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        #weighted = [1, batch size, hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        #rnn_input = [1, batch size, (hid dim * 2) + emb dim]\n",
        "        \n",
        "        output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        assert (output == hidden).all()\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output   = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HnKXsdiSzJC"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqPackedAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        #src: [src len, batch size]\n",
        "        \n",
        "        mask = (src == self.src_pad_idx).permute(1, 0)\n",
        "        #mask: [batch size, src len]\n",
        "        #we need to permute to make the mask same shape as attention...\n",
        "        return mask\n",
        "\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src: [src len, batch size]\n",
        "        #src len: [batch size]\n",
        "        #trg: [trg len, batch size]\n",
        "        \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len    = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim #define in decoder\n",
        "        \n",
        "        #because decoder decodes each step....let's create a list that gonna append the result to this guy\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #because decoder decodes each step....let's memorize the attention done in each step....\n",
        "        attentions = torch.zeros(trg_len, batch_size, src.shape[0]).to(self.device)\n",
        "        \n",
        "        #let's start!!!\n",
        "        #1. encoder\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "        #encoder_outputs: [src len, batch size, hid dim * num directions]\n",
        "        #hidden: [batch size, hid dim]\n",
        "        \n",
        "        #set the first input to the decoder\n",
        "        input_ = trg[0,:]  #basically <sos>\n",
        "        \n",
        "        #create the mask for use in this step\n",
        "        mask = self.create_mask(src)\n",
        "        \n",
        "        #2. for each of trg word\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            #3. decode (hidden is always carry forward)\n",
        "            output, hidden, attention = self.decoder(input_, hidden, encoder_outputs, mask)\n",
        "            #output:   [batch size, output_dim]\n",
        "            #hidden:   [batch size, hid_dim]\n",
        "            #attention::[batch size, src len]  ==> how each of src token is important to input_ \n",
        "            \n",
        "            #4. append the results to outputs and attentions\n",
        "            outputs[t] = output\n",
        "            attentions[t] = attention\n",
        "            \n",
        "            #5. get the result, using argmax\n",
        "            top1 = output.argmax(1)  #find the maximum index of dimension 1, which is output_dim\n",
        "            \n",
        "            #6. based on the teacher forcing ratio, \n",
        "            teacher_force_or_not = random.random() < teacher_forcing_ratio\n",
        "                    #if teacher forcing, next input is the next trg\n",
        "                    #if no teacher forcing, the next input is the argmax guy...\n",
        "            input_ = trg[t] if teacher_force_or_not else top1  #autoregressive\n",
        "            \n",
        "        return outputs, attentions #outputs for predicting the word, attentions to see which word is important"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rji6Jm2NS4_W"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ2XL8c3S6jy",
        "outputId": "05eaef67-8f49-44af-bdca-2054a1bc3a0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Seq2SeqPackedAttention(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7585, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "      (W): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (U): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(6766, 256)\n",
              "    (gru): GRU(1280, 512)\n",
              "    (fc): Linear(in_features=1792, out_features=6766, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_dim   = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_dim  = len(vocab_transform[TRG_LANGUAGE])\n",
        "emb_dim     = 256  \n",
        "hid_dim     = 512  \n",
        "dropout     = 0.5\n",
        "SRC_PAD_IDX = PAD_IDX\n",
        "\n",
        "attn = Attention(hid_dim, variants='additive')\n",
        "enc  = Encoder(input_dim,  emb_dim,  hid_dim, dropout)\n",
        "dec  = Decoder(output_dim, emb_dim,  hid_dim, dropout, attn)\n",
        "\n",
        "model_additive = Seq2SeqPackedAttention(enc, dec, SRC_PAD_IDX, device).to(device)\n",
        "model_additive.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1zCM824S9GA",
        "outputId": "2b2e8980-d108-4122-8aad-e8f5a1442508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1941760\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "393216\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "524288\n",
            "   512\n",
            "   512\n",
            "262144\n",
            "   512\n",
            "524288\n",
            "   512\n",
            "1732096\n",
            "1966080\n",
            "786432\n",
            "  1536\n",
            "  1536\n",
            "12124672\n",
            "  6766\n",
            "______\n",
            "22239086\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
        "    for item in params:\n",
        "        print(f'{item:>6}')\n",
        "    print(f'______\\n{sum(params):>6}')\n",
        "    \n",
        "count_parameters(model_additive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP8Z1oRBS_s6"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "#training hyperparameters\n",
        "optimizer = optim.Adam(model_additive.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX) #combine softmax with cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "894sAF54TDUh"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, criterion, clip, loader_length):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for src, src_length, trg in loader:\n",
        "        \n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attentions = model(src, src_length, trg)\n",
        "        \n",
        "        #trg    = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        #the loss function only works on 2d inputs with 1d targets thus we need to flatten each of them\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg    = trg[1:].view(-1)\n",
        "        #trg    = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        #clip the gradients to prevent them from exploding (a common issue in RNNs)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaAAdKcFTHFf"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, loader_length):\n",
        "        \n",
        "    #turn off dropout (and batch norm if used)\n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for src, src_length, trg in loader:\n",
        "        \n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, attentions = model(src, src_length, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg    = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg    = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / loader_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLItUB7fTHWd"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wIrA7q9TLl5",
        "outputId": "5e33ef20-b224-4c59-dbf5-1fb9c514ea9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 5m 26s\n",
            "\tTrain Loss: 2.479 | Train PPL:  11.929\n",
            "\t Val. Loss: 1.532 |  Val. PPL:   4.627\n",
            "Epoch: 02 | Time: 5m 19s\n",
            "\tTrain Loss: 1.122 | Train PPL:   3.070\n",
            "\t Val. Loss: 1.136 |  Val. PPL:   3.113\n",
            "Epoch: 03 | Time: 5m 11s\n",
            "\tTrain Loss: 0.752 | Train PPL:   2.121\n",
            "\t Val. Loss: 1.009 |  Val. PPL:   2.744\n",
            "Epoch: 04 | Time: 5m 11s\n",
            "\tTrain Loss: 0.585 | Train PPL:   1.794\n",
            "\t Val. Loss: 1.006 |  Val. PPL:   2.735\n",
            "Epoch: 05 | Time: 5m 10s\n",
            "\tTrain Loss: 0.489 | Train PPL:   1.631\n",
            "\t Val. Loss: 0.991 |  Val. PPL:   2.693\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "num_epochs = 5\n",
        "clip       = 1\n",
        "\n",
        "save_path = f'/content/{model_additive.__class__.__name__}_fullSCB.pt'\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model_additive, train_loader, optimizer, criterion, clip, train_loader_length)\n",
        "    valid_loss = evaluate(model_additive, valid_loader, criterion, val_loader_length)\n",
        "    \n",
        "    #for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model_additive.state_dict(), save_path)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "CTUBtLzBbf87",
        "outputId": "7ad99598-843c-420d-f0e6-2af573923a43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAADQCAYAAABhoyiUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAo/ElEQVR4nO3deXwV1dnA8d+T5GZfSQJZSAgISMjCKoupghtFVBA3bEEFfbXa1q2tr7hrW5W2vlWxLqWKdaW1IBYFxRVRFJSdhEVZgoSwJZANkpDlvH/MTQzhZiG5k5vl+X4+95O5d87MeeZ6eTwzc+YcMcaglFKqYV6eDkAppdo7TZRKKdUETZRKKdUETZRKKdUETZRKKdUETZRKKdUEH08HcKqioqJMUlKSp8NQSnUya9asyTPGRLta1+ESZVJSEqtXr/Z0GEqpTkZEdje0zrZTbxFJEJHPRGSziGSJyO0uyowVkUIRWe98PWhXPEop1VJ2tigrgd8aY9aKSAiwRkQ+MsZsrlfuC2PMxTbGoZRSrWJbi9IYs88Ys9a5XAxsAeLtqk8ppezSJtcoRSQJGAKscrF6tIhsAHKB3xljstoiJqU6ooqKCnJycigrK/N0KB2Wv78/PXv2xOFwNHsb2xOliAQDC4A7jDFF9VavBXoZY0pEZALwDtDPxT5uAm4CSExMbHbdxyurefqT7+jXPYRLh2hjVnV8OTk5hISEkJSUhIh4OpwOxxhDfn4+OTk59O7du9nb2dqPUkQcWEnyDWPM2/XXG2OKjDElzuUlgENEolyUm2OMGW6MGR4d7fLuvUs+XsLKnYd55N0sDh893vIDUaqdKCsrIzIyUpNkC4kIkZGRp9wit/OutwAvAVuMMX9toEyMsxwiMsIZT767YvDyEh6bnEZxWSWPLdnirt0q5VGaJFunJd+fnS3KDOAa4Nw63X8miMjNInKzs8wVQKbzGuVs4Grj5gEyT48J4aaz+zB/TQ5f7chz566V6nIKCgp47rnnWrTthAkTKCgoaHb5hx9+mCeeeKJFdbmbnXe9vzTGiDEm3Rgz2PlaYox5wRjzgrPM34wxKcaYQcaYUcaYr+yI5bbz+pHYLZD7F2ZSVlFlRxVKdQmNJcrKyspGt12yZAnh4eE2RGW/LvGst7/Dm0cnp7Iz7yjPLdvh6XCU6rBmzpzJjh07GDx4MHfddRfLli3jrLPOYuLEiQwcOBCASy+9lGHDhpGSksKcOXNqt01KSiIvL4/s7GySk5O58cYbSUlJYdy4cZSWljZa7/r16xk1ahTp6elMnjyZI0eOADB79mwGDhxIeno6V199NQCff/45gwcPZvDgwQwZMoTi4uJWH3eHe4Sxpc7qF82lg+N4ftl2Jg6Ko2/3YE+HpFSrPPJuFptz63ckaZ2BcaE8dElKg+tnzZpFZmYm69evB2DZsmWsXbuWzMzM2rvIc+fOpVu3bpSWlnLGGWdw+eWXExkZecJ+vv/+e+bNm8c//vEPrrrqKhYsWMC0adMarPfaa6/lmWeeYcyYMTz44IM88sgjPPXUU8yaNYtdu3bh5+dXe1r/xBNP8Oyzz5KRkUFJSQn+/v6t+1LoIi3KGvdfPJBAXx/uXbiJ6mqdK0gpdxgxYsQJXW1mz57NoEGDGDVqFHv27OH7778/aZvevXszePBgAIYNG0Z2dnaD+y8sLKSgoIAxY8YAcN1117F8+XIA0tPTmTp1Kq+//jo+Pla7LyMjg9/85jfMnj2bgoKC2s9bo8u0KAGigv24d8IA7l6wiflrcrjqjARPh6RUizXW8mtLQUFBtcvLli3j448/5uuvvyYwMJCxY8e67Irj5+dXu+zt7d3kqXdDFi9ezPLly3n33Xd59NFH2bRpEzNnzuSiiy5iyZIlZGRksHTpUgYMGNCi/dfoUi1KgCuHJTAiqRuPLtlCXkm5p8NRqkMJCQlp9JpfYWEhERERBAYGsnXrVlauXNnqOsPCwoiIiOCLL74A4LXXXmPMmDFUV1ezZ88ezjnnHP70pz9RWFhISUkJO3bsIC0tjbvvvpszzjiDrVu3tjqGLpcovbyExy5L5djxSh5drH0rlToVkZGRZGRkkJqayl133XXS+vHjx1NZWUlycjIzZ85k1KhRbqn3lVde4a677iI9PZ3169fz4IMPUlVVxbRp00hLS2PIkCHcdttthIeH89RTT5Gamkp6ejoOh4MLL7yw1fVLR5vXe/jw4cYd41H+9cNtzP50O6/dMIKz+jX/aR+lPGnLli0kJyd7OowOz9X3KCJrjDHDXZXvci3KGr88py+9o4K4/x3tW6mUalyXTZT+Dm8evTSV3fnHeObTk+/KKaVUjS6bKAHO7BvF5UN78vfPd7Jtf+s7pSqlOqcunSgB7rsomRB/7VuplGpYl0+U3YJ8ue+igazZfYR53/7g6XCUUu1Ql0+UAJcPjWd0n0hmvb+Vg8U6crRS6kSaKLHGp3t0cirlFdX8/t36c58ppVojONgaVyE3N5crrrjCZZmxY8e6nIa6oc/bmiZKpz7RwfzqnL68t3Efn2076OlwlOp04uLimD9/vqfDaBFNlHXcPLYPp0UH8cA7mRw73vjYekp1RTNnzuTZZ5+tfV8zuG5JSQnnnXceQ4cOJS0tjf/+978nbZudnU1qaioApaWlXH311SQnJzN58uRmPes9b9480tLSSE1N5e677wagqqqK6dOnk5qaSlpaGk8++STgevi11uhSg2I0xc/Hm8cmpzFlzkqe/uR77rlQn4BQ7dj7M2H/JvfuMyYNLpzV4OopU6Zwxx138Ktf/QqAt956i6VLl+Lv78/ChQsJDQ0lLy+PUaNGMXHixAanXXj++ecJDAxky5YtbNy4kaFDhzYaVm5uLnfffTdr1qwhIiKCcePG8c4775CQkMDevXvJzMwEqB1qzdXwa62hLcp6RvaJZMrwBF78Ypfbx/pTqqMbMmQIBw8eJDc3lw0bNhAREUFCQgLGGO69917S09M5//zz2bt3LwcOHGhwP8uXL68dfzI9PZ309PRG6/32228ZO3Ys0dHR+Pj4MHXqVJYvX06fPn3YuXMnt956Kx988AGhoaG1+6w//FpraIvShXsmDODjLQe4d+EmFtxyJt5eOpmTaocaafnZ6corr2T+/Pns37+fKVOmAPDGG29w6NAh1qxZg8PhICkpqU3mHo+IiGDDhg0sXbqUF154gbfeeou5c+e6HH6tNQlTW5QuhAf68sDFA1m/p4A3Vu32dDhKtStTpkzhX//6F/Pnz+fKK68ErOHVunfvjsPh4LPPPmP37sb/3Zx99tm8+eabAGRmZrJx48ZGy48YMYLPP/+cvLw8qqqqmDdvHmPGjCEvL4/q6mouv/xy/vjHP7J27doGh19rDW1RNmDS4DgWrM3hzx9s46cpMfQIbf1w8kp1BikpKRQXFxMfH09sbCwAU6dO5ZJLLiEtLY3hw4c3OVDuLbfcwowZM0hOTiY5OZlhw4Y1Wj42NpZZs2ZxzjnnYIzhoosuYtKkSWzYsIEZM2ZQXV0NwOOPP147/FphYSHGmNrh11qjyw6z1hy7848y7snlnDugO89Pa/w/pFJtQYdZcw8dZs2NekUGcdt5/Xg/cz8fb274wrRSqnPTRNmEG8/qQ/8ewTy0KIuj5dq3UqmuSBNlE3x9vHj8sjT2FpTy5EffeTocpZQHaKJshmG9uvHzkYnMXbGLzL2Fng5HdXEd7b5Ce9OS708TZTPdPX4A3YL8uOftTVTpuJXKQ/z9/cnPz9dk2ULGGPLz8/H3P7VeLNo9qJnCAhw8dMlAbp23jle+yub6n/RueiOl3Kxnz57k5ORw6NAhT4fSYfn7+9OzZ89T2sa2RCkiCcCrQA/AAHOMMU/XKyPA08AE4Bgw3Riz1q6YWuvi9FgWrM3h/z7cxvjUGOLCAzwdkupiHA4HvXvr/6Tbmp2n3pXAb40xA4FRwK9EZGC9MhcC/Zyvm4DnbYyn1USEP0xKpcoYHlqU5elwlFJtxLZEaYzZV9M6NMYUA1uA+HrFJgGvGstKIFxEYu2KyR0SugVy5/n9+WjzAZZm7fd0OEqpNtAmN3NEJAkYAqyqtyoe2FPnfQ4nJ9N25/qf9GZATAgP/TeL4rIKT4ejlLKZ7YlSRIKBBcAdxpgWjVsmIjeJyGoRWd0eLmI7vK2+lQeKy/i/D7VvpVKdna2JUkQcWEnyDWPM2y6K7AUS6rzv6fzsBMaYOcaY4caY4dHR0fYEe4qGJEZwzahevPJ1Nhv2FHg6HKWUjWxLlM472i8BW4wxf22g2CLgWrGMAgqNMfvsisndfvfT0+keYvWtrKyq9nQ4Simb2NmizACuAc4VkfXO1wQRuVlEbnaWWQLsBLYD/wB+aWM8bhfq7+DhS1LYvK+Il1dkezocpZRNbOtHaYz5Emh0aHBjPV7wK7tiaAvjU2M4P7k7f/3oOy5Mi6FnRKCnQ1JKuZk+wthKIsIjk1IRgQf/m6WPlinVCWmidIP48AB+c0F/Pt16kPcztW+lUp2NJko3mX5mEqnxoTy8KIsi7VupVKeiidJNfLy9eHxyOnkl5fzlg22eDkcp5UaaKN0orWcY152ZxOurdrNm9xFPh6OUchNNlG7223GnExPqz30LN1GhfSuV6hQ0UbpZsJ8Pj0xMYev+Yl78Ypenw1FKuYEmShuMS4nhpyk9ePqT7/gh/5inw1FKtZImSps8PDEFHy8v7v9vpvatVKqD00Rpk9iwAH43rj/LvzvEog25ng5HKdUKmihtdM3oJAb1DOMP722m8Jj2rVSqo9JEaSNvL+Gxy9I4cqyCWR9s8XQ4SqkW0kRps5S4MK7PSGLeN3v4Nvuwp8NRSrWAJso2cOcF/YkPD+DetzdxvFL7VirV0WiibAOBvj784dIUvj9YwpzlOzwdjlLqFGmibCPnDujBRWmxzP50O7vyjno6HKXUKdBE2YYevGQgft5e3P/OJu1bqVQHoomyDfUI9ed/LxzAiu35LFx30hxqSql2ShNlG5s6IpEhieH8cfEWjhw97ulwlFLNoImyjXl5CY9flkZRaQWPLdG+lUp1BJooPWBATCj/c1Yf/rMmh6935Hs6HKVUEzRResjt5/UjoVsA972zifLKKk+Ho5RqhCZKDwnw9eaPl6ax89BRnl+mfSuVas80UXrQmP7RTBwUx3Of7WD7wRJPh6OUaoAmSg974OKB+Du8uG+h9q1Uqr3SROlh0SF+3DMhmVW7DvOfNTmeDkcp5UKzEqWI3C4ioWJ5SUTWisg4u4PrKqYMT2B4rwgeW7KF/JJyT4ejlKqnuS3K640xRcA4IAK4BphlW1RdTE3fyqPllTy6WPtWKtXeNDdRivPvBOA1Y0xWnc/at4I9UN3+hzbr1yOEX5x9Gm+v28uK7XmeDkcpVUdzE+UaEfkQK1EuFZEQoNHsIyJzReSgiGQ2sH6siBSKyHrn68FTC70Zqqvg1Unw7AhY+ypUtu/T2l+f25ekyEDuW7iJsgrtW6lUe9HcRHkDMBM4wxhzDHAAM5rY5p/A+CbKfGGMGex8/b6ZsZyac+8DRwAsuhWeHgQrZkNZkS1VtZa/w5tHJ6eRnX+MZz/b7ulwlFJOzU2Uo4FtxpgCEZkG3A8UNraBMWY54Nm5D7y8IfVy+MVymPY2RPWDjx6AJ1Ph40eg5KBHw3Mlo28Ulw2J54XPd/D9gWJPh6OUovmJ8nngmIgMAn4L7ABedUP9o0Vkg4i8LyIpDRUSkZtEZLWIrD506NCp1yICfc+D696FGz+F08bCl09aCfO9O+HwzlYcgvvdd1EyQX4+3LtwE9XV2rdSKU9rbqKsNFZv6EnA34wxzwIhrax7LdDLGDMIeAZ4p6GCxpg5xpjhxpjh0dHRras1fhhc9Sr8ejUMuhrWvQ7PDIP/TIfc9a3bt5tEBvtx74Rkvs0+wr9X7/F0OEp1ec1NlMUicg9Wt6DFIuKFdZ2yxYwxRcaYEufyEsAhIlGt2ecpieoLE2fDHZvgzNtg+ycwZ4x182fnMvDwUzJXDuvJyN7deHzJFg4Vt++bUEp1ds1NlFOAcqz+lPuBnsBfWlOxiMSIiDiXRzhjafsxx0Ji4IJH4M5MOP9hOLjFSpZzxkLWQuvOuQeICI9OTqOsopo/vLfZIzEopSzNSpTO5PgGECYiFwNlxphGr1GKyDzga+B0EckRkRtE5GYRudlZ5AogU0Q2ALOBq40nH3b2D4Of3Am3b4RLnobyYut0/G/DYfVcqChr85D6dg/mlrGnsWhDLp9/14Jrs0opt5Dm5CYRuQqrBbkMq6P5WcBdxpj5tkbnwvDhw83q1avtr6i6Cra+B18+BblrIag7jLoFzrjBSqptpLyyiguf+oKK6mo+vGMMAb7ebVa3Ul2JiKwxxgx3ta65p973YfWhvM4Ycy0wAnjAXQG2S17eMHCSdZf82kUQkwqfPAJ/TYEPH4CifW0Shp+P1bdyz+FSZn/6fZvUqZQ6UXMTpZcxpm6nw/xT2LZjE4E+Y+CahVZ/zP7j4Ou/wdPpVif2PPs7ho8+LZIrh/XkH8t3snV/++wsr1Rn1txk94GILBWR6SIyHVgMLLEvrHYqdhBcMRduXQNDroGNb1nXMP89DXLW2Fr1vROSCQ1wcM/b2rdSqbbW3Js5dwFzgHTna44x5m47A2vXuvWBi/8Kd2TCWb+FXcvhxXPhnxfD9x/b0rUoIsiX+y9KZt0PBbzxzQ9u379SqmHNupnTnrTZzZxTUV4Ma16Br5+F4lzokQY/uQMGXgrePm6rxhjDtJdWsXFPIZ/8dgzdQ/3dtm+luroW38wRkWIRKXLxKhYRvVhWwy8Ezvw13L4BJj0LVeWw4AZ4Zih88w84fswt1YgIf7w0jfKqah55V/tWKtVWGk2UxpgQY0yoi1eIMSa0rYLsMHx8Ycg0+OUquPpNCO4OS34HT6XB53+BY60fI6R3VBC3ntOXxZv28enWA24IWinVlK5x57qteXnBgIvgho9g+hKIHwqf/dEahOODe6GwdXPj/GLMafTtHswD72Rx7Hilm4JWSjVEE6WdRCApA6b+B275CpIvhlUvWONiLrwFDm5t0W59fbx4/LI09haU8tTH2rdSKbtpomwrPVLgsjlw2zoYfoP1HPlzI2Hez+CHVae8uzOSuvGzEQm89OUusnIbHRpUKdVKmijbWkQvmPBnuDMLxsyEH76GueNg7njY9sEpze8zc3wyEYFW38oq7VuplG00UXpKUCScc4+VMMf/yZoEbd4UeP5M2PAvqKpochdhgQ4euHggG3MKee3rbPtjVqqL0kTpab5BMOpmuH09TP67dV1z4S9g9hBY+TwcP9ro5hMHxXFWvyj+snQb+wpL2yZmpboYTZTthbfDGnH9lq/g529BWAJ8MBOeTIHPHoejrofqFBEevTSNymrDw4uy2jhopboGTZTtjQj0/ylc/z5c/yEkjobPZ1kJc8n/QsHJjy8mRgZy+/n9WJp1gA+z9nsgaKU6N02U7VniSPjZPKsDe+plsPoleHowLLgR9p84XfqNZ/Xh9B4hPLQoi5Jy7VuplDtpouwIug+AS5+zHpEceTNsXQwvZMDrV0D2CjAGh7cXj12Wxv6iMv7vw22ejlipTkUTZUcS1hPGP2bN73PO/ZC7Dv45AV66ALa8x7CEMKaOTOSVr7LZmFPg6WiV6jQ0UXZEgd1gzF3WDJITnoCSA/DvqfDcSO6NXUuPIC/ueXsTlVXN75OplGqYJsqOzDcQRtwIt66Dy18Cbz8C37+NT31uZ/SBebyxXO+CK+UOOh5lZ2IM7PgE8+VTSPYXFJogvIdOJbjXUIjsC5GnWa1RpdRJGhuP0n2jyirPE4G+5yN9z+fA5hVs+PfDnLfuRVhX5xQ8oJszaToTZ2RfiOpnjdruCPBc7Eq1Y5ooO6keAzPY99N/MGDRBvo68vjZace5MPYo0cf3QP4O2PkZbHjzxI3CEn5MnnWTaViiW0dqV6qj0VPvTm7LviJeXrGLd9bncryymrP6RTEjI4mx/bvjVVECh3dC/nYreeZvt15526G8zohEXg7o1vvEVmjNK7iH1ZJVqoNr7NRbE2UXkV9SzrxvfuC1lbs5UFRO76ggrhvdiyuGJxDsV6+1aAwcy/8xcda+dlivqvIfy/oGu26FdjsNAsLb9BiVag1NlKrW8cpq3s/cx8srslm/p4AQPx+uOiOB60YnkRgZ2PQOqqugaO/JrdD87dbjlabO9dCgaNet0Ije4NCJ0VT7oolSubT2hyO8vCKb9zfto8oYzk/uwYyMJEb3iURacjpdWQ5Hsl20QrdbfT1rCYQnnNwKjexrXSf18nbXISrVbJooVaP2F5bx2sps3lz1A0eOVTAgJoQZGUlMGhyPv8NNSausyHUrNH8HHC/+sZy3r3UH3lVLNChar4cq23gkUYrIXOBi4KAxJtXFegGeBiYAx4Dpxpi1Te1XE6V9yiqq+O/6vby8Iput+4vpFuTLz0ckcs3oXvSwaw5xY6DkoOtW6OGdUF1nAGO/sHrJ87Qf//qF2BOf6jI8lSjPBkqAVxtIlBOAW7ES5UjgaWPMyKb2q4nSfsYYvt6Zz9wvs/lk6wG8RZiQFsuMjCSGJEa0XSBVlVC4x3UrtHAPUOe3GxzjohV6GjgCna1QZ0u0ZrnRvzSv7KnsT1vC7Z7HTr1FJAl4r4FE+XdgmTFmnvP9NmCsMWZfY/vURNm2ducf5ZWvdvPW6j2UlFcyJDGcGRm9uTA1Boe3B5+ArSiFw7tOboXmb4djeZ6Lq0mtTLzU/GlOcva2+r96+VhdvLwd1vXf2mXnOpfLjnrbNnc/znW1yz7ObR2N1NXItl7ebfY/mfaaKN8DZhljvnS+/wS42xhzUhYUkZuAmwASExOH7d6927aYlWsl5ZXMX72Hf36VTXb+MWJC/blmdC9+NiKRbkG+ng7vRKVHIH+ndepeWWqd3gNgnMv1//Lj+7rLjf5taH/1Pm/V/lxseyr7M1VWL4WqCusSxgnLlVaL3eVyvb8nLDc9l5PbtSTJevvABb+HuCHNrqbDP8JojJkDzAGrRenhcLqkYD8fpmf05trRSSz77iBzv8zmL0u3MfuT77l0cDwzfpLEgJhQT4dpCYiAnsOsl3IvY6yEW5M0q5wJuHa5fmKtl2SrKluwbTMTe/0k78ZGoCcT5V4goc77ns7PVDvm5SWcO6AH5w7owXcHinl5RTYL1+Xw79V7OPO0SGZk9ObcAd3x9tJrcp2SiNVa8/YBuk5fWE8Os7YIuFYso4DCpq5Pqvalf48QHr8sjZX3nMfd4wewK+8oN766mnOeWMZLX+6iuMwDp2lK2cDOu97zgLFAFHAAeAhwABhjXnB2D/obMB6re9AMV9cn69ObOe1XZVU1S7MOMHfFLtbsPkKQrzdXDk/gujOT6B0V5OnwlGqUdjhXbW5jTgEvr8jmvY25VFYbzjm9O9dn9Cajbwuf+lHKZpoolcccLCrj9VU/8Oaq3eSVHKd/j2Cmn9mbyUPiCfDVRxVV+6GJUnlcWUUV723cx8srdpGVW0R4oIOrz0jk2tG9iAvXAYOV52miVO2GMYZvdh3m5RXZfLh5PyLC+NQYrs9IYmhihJ6WK4/p8P0oVechIozsE8nIPpHsOXyM11bu5l/f/MDijftI7xnGjIwkLkqLw9dH571T7Ye2KJXHHTteyYK1e/nnil3sOHSU6BA/po3sxdRRiUQF+3k6PNVF6Km36hCqqw3Lvz/Eyyuy+fy7Q/h6ezFxcBwzMpJIiQvzdHiqk9NTb9UheHkJY0/vztjTu7P9YAmvfJXNgrU5zF+Tw4je3bg+I4kLBsboUz+qzWmLUrVrhaUVvPWtNRjH3oJS4sMDuO7MXkw5I5GwAIenw1OdiJ56qw6vsqqaj7ccYO6KbL7ZdZhAX28uH9qT6RlJnBYd7OnwVCegiVJ1Klm5hby8IptF63M5XlXNmP7RzMhI4ux+0XjpablqIU2UqlPKKynnzVXWFLyHiss5LTqI6WcmcdnQngTVn4JXqSZoolSd2vHKahZvyuXlFdlszCkk1N+Hq0dYT/30jGjGFLxKoYlSdRHGGNb+cIS5K7L5IHM/xhhOjwklLT6U1PgwUuLCGBgbqs+YK5e0e5DqEkSEYb26MaxXN3ILSnlr9R7W/lDAx1sO8tbqHAC8BPp2DyY1LozUeOs1MC6UYD1VV43QX4fqlOLCA7jj/P6A1dLcV1hG5t5C65VbxBfb83h7nTWgvgj0jgoiNS6MtPgwUuJDSYkL0+5HqpYmStXpiQhx4QHEhQcwLiWm9vODRWVk5hayKaeIzNxCVmcfZtGG3Nr1vSIDSY2zEmdafBipcWFEtLeJ1FSb0ESpuqzuof6cG+rPuQN61H6WV1JOVm5Rbetz494CFm/6cYaS+PAAUuNDTzh1jw7R59E7O02UStURFezHmP7RjOkfXftZ4bEKMnN/PG3P3FvI0qwDtet7hPqdkDjT4sPoEeqnQ8Z1IpoolWpCWKCDjL5RZPSNqv2suKyCzblFbNpbWNsC/WzbQaqdnUiign1JcV7zTHVe8+wZEaDJs4PSRKlUC4T4O2rH1axx7HglW/YVkbnXSqCZewv5cnseVc7sGR7oOOmaZ2K3QH2aqAPQRKmUmwT6+tR2T6pRVlHF1v3FZO4tJCu3kE17C5n75S4qqqzkGeLnQ0q9a569o4J0hKR2RhOlUjbyd3gzOCGcwQnhtZ8dr6zmuwPFzmuehWzaW8SrK3dzvLIagEBfbwbGhtYmztT4UPpGB+PjraO+e4o+maNUO1BRVc2OQyVsyvnxmmdWbhGlFVUA+Pl4kRwbesI1z/49QnTKDDfSRxiV6oCqqg278kpOuOaZlVtESXklAL7eXpweE2J1V3Je8zw9JgR/hz6i2RKaKJXqJKqrDbsPH6s9bbf6exZRWFoBgI+X0K9HCKlxoZweE0JsWACx4f7EhvnTPcRfr302QhOlUp2YMYacI6V1kqd16p5/9PgJ5by9hB4hfsSGBxAT5k9cmD+xYQHEhfsTExZAXJg/UcF+XfYuvA6KoVQnJiIkdAskoVsgF6bFAlbyLCqtJLewlH2FpeQWlLG/sMx6X1DG5twiPt58gHLnDaQaPl5Cj1B/4sL9f2yNhvoTGx5AnPN9ZJBvl+sPqolSqU5IRAgLdBAW6CA5NtRlGWMMR45VkFtQyv7CMiuhFpaxr6CUfYVlrN9TwAeZZRyvOjGZ+np7ERNmnc7H1WudxjoTbESgo1MlU1sTpYiMB54GvIEXjTGz6q2fDvwF2Ov86G/GmBftjEkpZRERugX50i3Il9R419MBV1cb8o8er9MaLWVfURn7CqzE+s2uwxwoKqOy+sRLeP4OLytxhvk7E6mVROPCAmrfhwb4dJhkaluiFBFv4FngAiAH+FZEFhljNtcr+m9jzK/tikMp1XJeXkJ0iB/RIX6k9Ww4meaVlJ/QGq3bOl25I58DxeW1TyjVCPT1JramJRpmnd7H1mmpxob5E+LfPoa6s7NFOQLYbozZCSAi/wImAfUTpVKqA/PyErqH+tM91P+EjvV1VVZVc6ik3EqiztZobkEZ+4usv8u/P8TB4nLq31sO9vOpTaJx9VqnNQm2LeZHsrOGeGBPnfc5wEgX5S4XkbOB74A7jTF7XJRRSnVgPt41p+IBkOi6TEVVNQeLy9lXYLVG9zuT6b5Cq5W6ZV8Rh4rLT9ou1N+ntgVac/c+NjyAs/tF0T3U3z3xu2UvLfcuMM8YUy4ivwBeAc6tX0hEbgJuAkhMbOBbVkp1aA5vL+LDA4gPD2iwzPHKag4UlVk3oIrKahNpTet0Y86P3aLe+J+RHSJR7gUS6rzvyY83bQAwxuTXefsi8GdXOzLGzAHmgNWP0r1hKqU6Cl8fr9quUA0pq6jiQFEZ3UPckyQB7HxQ9Fugn4j0FhFf4GpgUd0CIhJb5+1EYIuN8SilugB/hze9IoPcOtumbS1KY0yliPwaWIrVPWiuMSZLRH4PrDbGLAJuE5GJQCVwGJhuVzxKKdVS+gijUkrR+COMOkaTUko1QROlUko1QROlUko1ocNdoxSRQ8DuU9wsCsizIZyOUH9XPnZP19+Vj70j1t/LGBPtakWHS5QtISKrG7pI29nr78rH7un6u/Kxd7b69dRbKaWaoIlSKaWa0FUS5ZwuXH9XPnZP19+Vj71T1d8lrlEqpVRrdJUWpVJKtVinSpQiMl5EtonIdhGZ6WK9n4j827l+lYgktWHd00XkkIisd77+x411zxWRgyKS2cB6EZHZztg2ishQd9XdzPrHikhhnWN/0M31J4jIZyKyWUSyROR2F2Vs+Q6aWbdtxy8i/iLyjYhscNb/iIsydv7um1O/bb995/69RWSdiLznYp17jt0Y0yleWANv7AD6AL7ABmBgvTK/BF5wLl+NNQ1FW9U9HWtOIDuO/WxgKJDZwPoJwPuAAKOAVW1c/1jgPRv/28cCQ53LIViDQNf//m35DppZt23H7zyeYOeyA1gFjKpXxpbf/SnUb9tv37n/3wBvuvqO3XXsnalFWTv1hDHmOFAz9URdk7AGBwaYD5wn7pndqDl128YYsxxr9KWGTAJeNZaVQHi9Ie7srt9Wxph9xpi1zuVirOH64usVs+U7aGbdtnEeT4nzrcP5qn/jwa7ffXPrt42I9AQuwhrP1hW3HHtnSpSupp6o/4OtLWOMqQQKgcg2qhusaS82ish8EUlwsd4uzY3PTqOdp2fvi0iKXZU4T62GYLVs6rL9O2ikbrDx+J2nnuuBg8BHxpgGj93Nv/vm1g/2/fafAv4XqG5gvVuOvTMlyvbuXSDJGJMOfMSP/5frCtZiPR42CHgGeMeOSkQkGFgA3GGMKbKjjhbWbevxG2OqjDGDsWYRGCEiqe7cvxvqt+W3LyIXAweNMWvcsb/GdKZE2eTUE3XLiIgPEAbk03rNmvbCGFMzM9KLwDA31NtczflubGOMKao5PTPGLAEcIhLlzjpExIGVqN4wxrztooht30FTdbfF8Tv3XQB8Boyvt8qu332z6rfxt58BTBSRbKzLXeeKyOv1yrjl2DtTomxy6gnn++ucy1cAnxrnVV676xbPTnuxCLjWeed3FFBojNnXVpWLSEzNdSERGYH1u3PbP1Tnvl8Cthhj/tpAMVu+g+bUbefxi0i0iIQ7lwOAC4Ct9YrZ9btvVv12/faNMfcYY3oaY5Kw/s19aoyZVq+Ye47drjtRnnhh3dn8DusO9H3Oz34PTHQu+wP/AbYD3wB92rDux4EsrDvinwED3Fj3PGAfUIF17e0G4GbgZud6AZ51xrYJGO7m772p+n9d59hXAme6uf6fYN1A2Aisd74mtMV30My6bTt+IB1Y56w/E3iwjX/3zanftt9+nTjG4rzrbcex65M5SinVhM506q2UUrbQRKmUUk3QRKmUUk3QRKmUUk3QRKmUUk3QRKk6FRHJbqozt4jc21bxqM5BE6XqijRRqlOiiVK1KyKSJHXGtRSR34nIwyKyTESedo5nmOl8wgURiRSRD51jIb6I1bG8Ztt3RGSNc91Nzs9mAQHO/bzh/Gyac0zF9SLyd+cgD94i8k9nXZtE5M62/SZUe6KJUnUkgcYafOGXwFznZw8BXxpjUoCFQGKd8tcbY4YBw4HbRCTSGDMTKDXGDDbGTBWRZGAKkOHcdxUwFRgMxBtjUo0xacDL9h+eaq98PB2AUqdgHljjX4pIqPMZ47OBy5yfLxaRI3XK3yYik53LCUA/Tn7G+jysQRq+dT6OHYA1XNi7QB8ReQZYDHxoyxGpDkETpWpvKjnxTMe/znL9520bfP5WRMYC5wOjjTHHRGRZvX3VFgVeMcbc42Ifg4CfYj23fRVwfdPhq85IT71Ve3MA6O689ugHXFxn3RQAEfkJ1ug/hcBy4OfOzy8EIpxlw4AjziQ5AGv6hxoVzqHRAD4BrhCR7s59dBORXs47517GmAXA/VhTXaguSluUql0xxlSIyO+xRnrZy4lDdpWJyDqs6QZqWnePAPNEJAv4CvjB+fkHwM0isgXYhjVqT405wEYRWeu8Tnk/8KGIeGGNgPQroBR42fkZwEktTtV16OhBqkNwnjr/zhiz2tOxqK5HT72VUqoJ2qJUSqkmaItSKaWaoIlSKaWaoIlSKaWaoIlSKaWaoIlSKaWaoIlSKaWa8P9kNHrwiN49IgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(valid_losses, label = 'valid loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zohUsqhvbgSZ",
        "outputId": "d2ea3a7d-3261-40c4-ebec-11c4830126a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Test Loss: 0.971 | Test PPL:   2.642 |\n"
          ]
        }
      ],
      "source": [
        "model_additive.load_state_dict(torch.load(save_path))\n",
        "test_loss = evaluate(model_additive, test_loader, criterion, test_loader_length)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCnPjq-kbnmH"
      },
      "source": [
        "#7. Test on some random dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVFZjfJcbkIK",
        "outputId": "44ab5c53-636e-4c13-cf8b-ea37c6c03cfc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Some boats are on the lake', 'केही डुङ्गाहरु ताल छन्')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0][0], dataset[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC9N2MXVbt3b",
        "outputId": "4d4de35d-b974-43ee-d8b1-ca8260ee438f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([   2,  813,    4, 4391,    4,   42,    4,   48,    4,   10,    4, 1202,\n",
              "            3], device='cuda:0'),\n",
              " tensor([   2,   47,    0, 1120,   31,    3], device='cuda:0'))"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src_text = text_transform[SRC_LANGUAGE](dataset[0][0]).to(device)\n",
        "trg_text = text_transform[TRG_LANGUAGE](dataset[0][1]).to(device)\n",
        "src_text, trg_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPJFdyVKbydN",
        "outputId": "566a8cff-60d0-4d0b-d8bf-57a0fff5b68a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([13, 1]), torch.Size([6, 1]))"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src_text = src_text.reshape(-1, 1)  #because batch_size is 1\n",
        "trg_text = trg_text.reshape(-1, 1)\n",
        "src_text.shape, trg_text.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WGzZQc7b05p"
      },
      "outputs": [],
      "source": [
        "text_length = torch.tensor([src_text.size(0)]).to(dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r48DoPJkb4yT"
      },
      "outputs": [],
      "source": [
        "model_additive.load_state_dict(torch.load(save_path))\n",
        "\n",
        "model_additive.eval()\n",
        "with torch.no_grad():\n",
        "    output, attentions = model_additive(src_text, text_length, trg_text, 0) #turn off teacher forcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNDyXdazb2t9",
        "outputId": "94bac4cc-9156-4a83-8cfb-52303758fd95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([6, 1, 6766])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.shape #trg_len, batch_size, trg_output_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEacF3jib7vr",
        "outputId": "a983deca-e396-4801-ba2a-3a229dfb3540"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([6, 6766])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = output.squeeze(1)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p66uRv53cAsg",
        "outputId": "c2896147-7dd6-4288-d174-dd1996fae39e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([   0,   47,    0, 1120,   31,    3], device='cuda:0')"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_max = output.argmax(1) #returns max indices\n",
        "output_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UIPnHvrcFqU",
        "outputId": "26c73329-830d-448f-97a5-30e309c049a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<unk>\n",
            "What\n",
            "<unk>\n",
            "stuck\n",
            "want\n",
            "<eos>\n"
          ]
        }
      ],
      "source": [
        "for token in output_max:\n",
        "    print(mapping[token.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ-yWLuDf2it"
      },
      "source": [
        "#8. Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj2D2vY0cLNN",
        "outputId": "e64567a9-fa49-4b32-b5f0-715cc494a272"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([6, 1, 13])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "attentions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55l9A6Q0f6n8",
        "outputId": "810d4081-ef92-4857-d2f5-6568a5264a14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'क',\n",
              " 'े',\n",
              " 'ह',\n",
              " 'ी ',\n",
              " 'ड',\n",
              " 'ु',\n",
              " 'ङ्गा',\n",
              " 'ह',\n",
              " 'र',\n",
              " 'ु ',\n",
              " 'त',\n",
              " 'ा',\n",
              " 'ल ',\n",
              " 'छ',\n",
              " 'न',\n",
              " '्',\n",
              " '<eos>']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src_tokens = ['<sos>'] + token_transform[SRC_LANGUAGE].tokenize(dataset[0][1]) + ['<eos>']\n",
        "src_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yctd3q0f7_Q",
        "outputId": "721293c6-218f-4baa-fc75-776e55cd82be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<sos>', '<unk>', 'What', '<unk>', 'stuck', 'want', '<eos>']"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trg_tokens = ['<sos>'] + [mapping[token.item()] for token in output_max]\n",
        "trg_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UemlPn_RgAVU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=10)\n",
        "    \n",
        "    y_ticks =  [''] + translation\n",
        "    x_ticks =  [''] + sentence \n",
        "     \n",
        "    ax.set_xticklabels(x_ticks, rotation=45)\n",
        "    ax.set_yticklabels(y_ticks)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "Za5eOOj5gEOk",
        "outputId": "6075c04f-bbad-4dbe-c0ed-5f72915f7443"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-74-b23710e830bc>:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(x_ticks, rotation=45)\n",
            "<ipython-input-74-b23710e830bc>:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels(y_ticks)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2375 (\\N{DEVANAGARI VOWEL SIGN E}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2361 (\\N{DEVANAGARI LETTER HA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2337 (\\N{DEVANAGARI LETTER DDA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2329 (\\N{DEVANAGARI LETTER NGA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2381 (\\N{DEVANAGARI SIGN VIRAMA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py:128: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_attention(src_tokens, trg_tokens, attentions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqmuYUHVgNQX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
